{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import time\n",
    "import urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links = pd.read_csv('../../data/filtered_link.csv')\n",
    "\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_titles(links):\n",
    "    \"\"\"\n",
    "    Funct. for get all news content with beatifulsoup module\n",
    "\n",
    "    Params:\n",
    "    - Links (DataFrame): list of news links whose content you want to take\n",
    "\n",
    "    Return:\n",
    "    - news content (html <p> only)\n",
    "    \"\"\"\n",
    "    titles_result = []\n",
    "    \n",
    "    for i, link in enumerate(links['links']):\n",
    "        print(f\"Mengambil judul artikel dari halaman ke-{i + 1}\")\n",
    "        try:\n",
    "            response = requests.get(link, verify=False)\n",
    "            response.raise_for_status()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Gagal mengakses {link}: {e}\")\n",
    "            continue\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        article_titles = soup.find_all('div', class_='obj_article_summary')\n",
    "        \n",
    "        if not article_titles:\n",
    "            print(f\"Tidak ditemukan judul artikel di halaman {link}\")\n",
    "            continue\n",
    "\n",
    "        for article in article_titles:\n",
    "            title_tag = article.find('a')\n",
    "            if title_tag:\n",
    "                titles_result.append(title_tag.text.strip())\n",
    "            else:\n",
    "                print(f\"Tidak dapat menemukan judul artikel pada salah satu item di halaman {link}\")\n",
    "\n",
    "    return titles_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mengambil judul artikel dari halaman ke-1\n",
      "Mengambil judul artikel dari halaman ke-2\n",
      "Mengambil judul artikel dari halaman ke-3\n",
      "Mengambil judul artikel dari halaman ke-4\n",
      "Mengambil judul artikel dari halaman ke-5\n",
      "Mengambil judul artikel dari halaman ke-6\n",
      "Mengambil judul artikel dari halaman ke-7\n",
      "Mengambil judul artikel dari halaman ke-8\n",
      "Mengambil judul artikel dari halaman ke-9\n",
      "Mengambil judul artikel dari halaman ke-10\n",
      "Mengambil judul artikel dari halaman ke-11\n",
      "Mengambil judul artikel dari halaman ke-12\n",
      "Mengambil judul artikel dari halaman ke-13\n",
      "Mengambil judul artikel dari halaman ke-14\n",
      "Mengambil judul artikel dari halaman ke-15\n",
      "Mengambil judul artikel dari halaman ke-16\n",
      "Mengambil judul artikel dari halaman ke-17\n",
      "Mengambil judul artikel dari halaman ke-18\n",
      "Mengambil judul artikel dari halaman ke-19\n",
      "Mengambil judul artikel dari halaman ke-20\n",
      "Mengambil judul artikel dari halaman ke-21\n",
      "Mengambil judul artikel dari halaman ke-22\n",
      "Mengambil judul artikel dari halaman ke-23\n",
      "Mengambil judul artikel dari halaman ke-24\n",
      "Mengambil judul artikel dari halaman ke-25\n",
      "Mengambil judul artikel dari halaman ke-26\n",
      "Mengambil judul artikel dari halaman ke-27\n",
      "Mengambil judul artikel dari halaman ke-28\n",
      "Mengambil judul artikel dari halaman ke-29\n",
      "Mengambil judul artikel dari halaman ke-30\n"
     ]
    }
   ],
   "source": [
    "titles_result = get_article_titles(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles = pd.DataFrame(titles_result, columns=['article'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles = df_titles.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles.to_csv('../../data/raw/JPTIIK_unlabeled.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
