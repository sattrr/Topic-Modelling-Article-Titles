{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "     ---------------------------------------- 11.6/11.6 MB 1.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: selenium in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.30.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (4.13.3)\n",
      "Collecting webdriver-manager\n",
      "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
      "Collecting numpy>=1.23.2\n",
      "  Downloading numpy-2.2.4-cp311-cp311-win_amd64.whl (12.9 MB)\n",
      "     -------------------------------------- 12.9/12.9 MB 839.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "     -------------------------------------- 509.2/509.2 kB 1.5 MB/s eta 0:00:00\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "     -------------------------------------- 347.8/347.8 kB 1.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (2.3.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (0.29.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (2025.1.31)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from selenium) (4.13.0)\n",
      "Requirement already satisfied: websocket-client~=1.8 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from beautifulsoup4) (2.6)\n",
      "Collecting requests\n",
      "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "     ---------------------------------------- 64.9/64.9 kB 1.2 MB/s eta 0:00:00\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from webdriver-manager) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (25.3.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (3.10)\n",
      "Requirement already satisfied: outcome in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio~=0.17->selenium) (1.17.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Collecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl (102 kB)\n",
      "     -------------------------------------- 102.4/102.4 kB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pycparser in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.22)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Installing collected packages: pytz, tzdata, python-dotenv, numpy, charset-normalizer, requests, pandas, webdriver-manager\n",
      "Successfully installed charset-normalizer-3.4.1 numpy-2.2.4 pandas-2.2.3 python-dotenv-1.1.0 pytz-2025.2 requests-2.32.3 tzdata-2025.2 webdriver-manager-4.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script dotenv.exe is installed in 'c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts f2py.exe and numpy-config.exe are installed in 'c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script normalizer.exe is installed in 'c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "service = Service(ChromeDriverManager().install())\n",
    "options = Options()\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "# options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "options.add_argument(\"--disable-cache\") \n",
    "options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\")\n",
    "options.add_argument(\"--disable-blink-features=AutomationControlled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(service=service, options=options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 URL\n",
      "0  https://ieeexplore.ieee.org/xpl/tocresult.jsp?...\n",
      "1  https://ieeexplore.ieee.org/xpl/tocresult.jsp?...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "json_path = \"../../data/raw/article_links.json\"\n",
    "\n",
    "# Membaca file JSON\n",
    "with open(json_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Konversi JSON ke DataFrame\n",
    "df = pd.DataFrame(data[\"URL\"], columns=[\"URL\"])\n",
    "\n",
    "print(df.head())  # Cek apakah data terbaca dengan benar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ini untuk jumlah halaman dibatasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "# List untuk menyimpan hasil scraping\n",
    "all_titles = []\n",
    "all_years = []\n",
    "all_authors = []\n",
    "\n",
    "# Batasan jumlah halaman yang ingin di-scrape (None jika ingin sampai akhir)\n",
    "MAX_PAGES = 5  # Ubah sesuai kebutuhan, atau None untuk tanpa batas\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        base_url = row[\"URL\"]  # Pastikan kolom URL ada di dataset\n",
    "        print(f\"\\n🔍 Scraping artikel dari: {base_url}\")\n",
    "\n",
    "        page_number = 1\n",
    "        while True:\n",
    "            # Jika MAX_PAGES ditentukan dan batas tercapai, berhenti\n",
    "            if MAX_PAGES and page_number > MAX_PAGES:\n",
    "                print(f\"⚠️ Mencapai batas maksimum {MAX_PAGES} halaman. Lanjut ke URL berikutnya.\")\n",
    "                break\n",
    "\n",
    "            # Bangun URL untuk halaman tertentu\n",
    "            url = f\"{base_url}&sortType=vol-only-newest&pageNumber={page_number}\"\n",
    "            print(f\"📄 Membuka halaman {page_number}: {url}\")\n",
    "\n",
    "            driver.get(url)\n",
    "\n",
    "            # Tunggu elemen muncul untuk memastikan halaman telah dimuat\n",
    "            try:\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CLASS_NAME, \"col\"))\n",
    "                )\n",
    "            except:\n",
    "                print(f\"⚠️ Halaman {page_number} gagal dimuat, lanjut ke URL berikutnya.\")\n",
    "                break\n",
    "\n",
    "            time.sleep(3)  # Beri jeda agar halaman termuat sempurna\n",
    "\n",
    "            # Parse halaman dengan BeautifulSoup\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            articles = soup.find_all(\"div\", class_=\"col result-item-align px-3\")\n",
    "\n",
    "            # Mengecek apakah artikel ditemukan\n",
    "            if not articles:\n",
    "                print(f\"⚠️ Halaman {page_number} kosong atau tidak ditemukan artikel baru. Berhenti.\")\n",
    "                break  # Jika halaman kosong, hentikan scraping URL ini\n",
    "\n",
    "            for article in articles:\n",
    "                # **Scraping Judul**\n",
    "                h2_tag = article.find(\"h2\")\n",
    "                title_tag = h2_tag.find(\"a\") if h2_tag else None\n",
    "                title = title_tag.text.strip() if title_tag else \"Judul Tidak Ditemukan\"\n",
    "                all_titles.append(title)\n",
    "\n",
    "                # **Scraping Tahun**\n",
    "                year_container = article.find(\"div\", class_=\"description text-base-md-lh\")\n",
    "                year_tag = year_container.find(\"span\") if year_container else None\n",
    "                year = year_tag.text.strip() if year_tag else \"Tahun Tidak Ditemukan\"\n",
    "                all_years.append(year)\n",
    "\n",
    "                # **Scraping Author**\n",
    "                author_spans = article.find_all(\"span\", attrs={\"_ngcontent-ng-c893371016\": True})\n",
    "                authors = \", \".join(set(span.text.strip() for span in author_spans))  # Hapus duplikasi\n",
    "                authors = authors.replace(\";\", \"\").strip(\", \")  # Bersihkan format\n",
    "                all_authors.append(authors)\n",
    "\n",
    "            print(f\"✅ Berhasil scraping {len(articles)} artikel dari halaman {page_number}\")\n",
    "\n",
    "            page_number += 1  # Lanjut ke halaman berikutnya\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"❌ Error: Kolom 'URL' tidak ditemukan. Pastikan nama kolom sesuai. Error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Terjadi kesalahan saat scraping {url}: {e}\")\n",
    "\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ini untuk jumlah di scrapping sampai akhir halaman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Scraping artikel dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639\n",
      "📄 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=1\n",
      "✅ Berhasil scraping 25 artikel dari halaman 1\n",
      "📄 Membuka halaman 2: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=2\n",
      "✅ Berhasil scraping 25 artikel dari halaman 2\n",
      "📄 Membuka halaman 3: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=3\n",
      "✅ Berhasil scraping 25 artikel dari halaman 3\n",
      "📄 Membuka halaman 4: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=4\n",
      "✅ Berhasil scraping 25 artikel dari halaman 4\n",
      "📄 Membuka halaman 5: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=5\n",
      "✅ Berhasil scraping 25 artikel dari halaman 5\n",
      "📄 Membuka halaman 6: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=6\n",
      "✅ Berhasil scraping 25 artikel dari halaman 6\n",
      "📄 Membuka halaman 7: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=7\n",
      "✅ Berhasil scraping 25 artikel dari halaman 7\n",
      "📄 Membuka halaman 8: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=8\n",
      "✅ Berhasil scraping 25 artikel dari halaman 8\n",
      "📄 Membuka halaman 9: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=9\n",
      "✅ Berhasil scraping 25 artikel dari halaman 9\n",
      "📄 Membuka halaman 10: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=10\n",
      "✅ Berhasil scraping 25 artikel dari halaman 10\n",
      "📄 Membuka halaman 11: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=11\n",
      "✅ Berhasil scraping 25 artikel dari halaman 11\n",
      "📄 Membuka halaman 12: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=12\n",
      "✅ Berhasil scraping 25 artikel dari halaman 12\n",
      "📄 Membuka halaman 13: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=13\n",
      "✅ Berhasil scraping 25 artikel dari halaman 13\n",
      "📄 Membuka halaman 14: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=14\n",
      "✅ Berhasil scraping 25 artikel dari halaman 14\n",
      "📄 Membuka halaman 15: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=15\n",
      "✅ Berhasil scraping 25 artikel dari halaman 15\n",
      "📄 Membuka halaman 16: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=16\n",
      "✅ Berhasil scraping 25 artikel dari halaman 16\n",
      "📄 Membuka halaman 17: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=17\n",
      "✅ Berhasil scraping 25 artikel dari halaman 17\n",
      "📄 Membuka halaman 18: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=18\n",
      "✅ Berhasil scraping 25 artikel dari halaman 18\n",
      "📄 Membuka halaman 19: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=19\n",
      "✅ Berhasil scraping 25 artikel dari halaman 19\n",
      "📄 Membuka halaman 20: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=20\n",
      "✅ Berhasil scraping 25 artikel dari halaman 20\n",
      "📄 Membuka halaman 21: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=21\n",
      "✅ Berhasil scraping 25 artikel dari halaman 21\n",
      "📄 Membuka halaman 22: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=22\n",
      "✅ Berhasil scraping 25 artikel dari halaman 22\n",
      "📄 Membuka halaman 23: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=23\n",
      "✅ Berhasil scraping 25 artikel dari halaman 23\n",
      "📄 Membuka halaman 24: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=24\n",
      "✅ Berhasil scraping 25 artikel dari halaman 24\n",
      "📄 Membuka halaman 25: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=25\n",
      "✅ Berhasil scraping 25 artikel dari halaman 25\n",
      "📄 Membuka halaman 26: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=26\n",
      "✅ Berhasil scraping 25 artikel dari halaman 26\n",
      "📄 Membuka halaman 27: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=27\n",
      "✅ Berhasil scraping 25 artikel dari halaman 27\n",
      "📄 Membuka halaman 28: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=28\n",
      "✅ Berhasil scraping 25 artikel dari halaman 28\n",
      "📄 Membuka halaman 29: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=29\n",
      "✅ Berhasil scraping 25 artikel dari halaman 29\n",
      "📄 Membuka halaman 30: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=30\n",
      "✅ Berhasil scraping 25 artikel dari halaman 30\n",
      "📄 Membuka halaman 31: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=31\n",
      "✅ Berhasil scraping 25 artikel dari halaman 31\n",
      "📄 Membuka halaman 32: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=32\n",
      "✅ Berhasil scraping 25 artikel dari halaman 32\n",
      "📄 Membuka halaman 33: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=33\n",
      "✅ Berhasil scraping 25 artikel dari halaman 33\n",
      "📄 Membuka halaman 34: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=34\n",
      "✅ Berhasil scraping 25 artikel dari halaman 34\n",
      "📄 Membuka halaman 35: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=35\n",
      "✅ Berhasil scraping 25 artikel dari halaman 35\n",
      "📄 Membuka halaman 36: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=36\n",
      "✅ Berhasil scraping 25 artikel dari halaman 36\n",
      "📄 Membuka halaman 37: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=37\n",
      "✅ Berhasil scraping 25 artikel dari halaman 37\n",
      "📄 Membuka halaman 38: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=38\n",
      "✅ Berhasil scraping 25 artikel dari halaman 38\n",
      "📄 Membuka halaman 39: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=39\n",
      "✅ Berhasil scraping 25 artikel dari halaman 39\n",
      "📄 Membuka halaman 40: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=40\n",
      "✅ Berhasil scraping 25 artikel dari halaman 40\n",
      "📄 Membuka halaman 41: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=41\n",
      "✅ Berhasil scraping 25 artikel dari halaman 41\n",
      "📄 Membuka halaman 42: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=42\n",
      "✅ Berhasil scraping 25 artikel dari halaman 42\n",
      "📄 Membuka halaman 43: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=43\n",
      "✅ Berhasil scraping 25 artikel dari halaman 43\n",
      "📄 Membuka halaman 44: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=44\n",
      "✅ Berhasil scraping 25 artikel dari halaman 44\n",
      "📄 Membuka halaman 45: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=45\n",
      "✅ Berhasil scraping 25 artikel dari halaman 45\n",
      "📄 Membuka halaman 46: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=46\n",
      "✅ Berhasil scraping 25 artikel dari halaman 46\n",
      "📄 Membuka halaman 47: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=47\n",
      "✅ Berhasil scraping 25 artikel dari halaman 47\n",
      "📄 Membuka halaman 48: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=48\n",
      "✅ Berhasil scraping 25 artikel dari halaman 48\n",
      "📄 Membuka halaman 49: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=49\n",
      "✅ Berhasil scraping 25 artikel dari halaman 49\n",
      "📄 Membuka halaman 50: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=50\n",
      "✅ Berhasil scraping 25 artikel dari halaman 50\n",
      "📄 Membuka halaman 51: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=51\n",
      "✅ Berhasil scraping 25 artikel dari halaman 51\n",
      "📄 Membuka halaman 52: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=52\n",
      "✅ Berhasil scraping 25 artikel dari halaman 52\n",
      "📄 Membuka halaman 53: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=53\n",
      "✅ Berhasil scraping 25 artikel dari halaman 53\n",
      "📄 Membuka halaman 54: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=54\n",
      "✅ Berhasil scraping 25 artikel dari halaman 54\n",
      "📄 Membuka halaman 55: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=55\n",
      "✅ Berhasil scraping 25 artikel dari halaman 55\n",
      "📄 Membuka halaman 56: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=56\n",
      "✅ Berhasil scraping 25 artikel dari halaman 56\n",
      "📄 Membuka halaman 57: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=57\n",
      "✅ Halaman terakhir tercapai di 56. Berhenti.\n",
      "\n",
      "🔍 Scraping artikel dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10380310&punumber=6287639\n",
      "📄 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10380310&punumber=6287639&sortType=vol-only-newest&pageNumber=1\n",
      "✅ Berhasil scraping 25 artikel dari halaman 1\n",
      "📄 Membuka halaman 2: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10380310&punumber=6287639&sortType=vol-only-newest&pageNumber=2\n",
      "✅ Berhasil scraping 25 artikel dari halaman 2\n",
      "📄 Membuka halaman 3: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10380310&punumber=6287639&sortType=vol-only-newest&pageNumber=3\n",
      "✅ Berhasil scraping 25 artikel dari halaman 3\n",
      "📄 Membuka halaman 4: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10380310&punumber=6287639&sortType=vol-only-newest&pageNumber=4\n",
      "✅ Berhasil scraping 25 artikel dari halaman 4\n",
      "📄 Membuka halaman 5: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10380310&punumber=6287639&sortType=vol-only-newest&pageNumber=5\n",
      "✅ Berhasil scraping 25 artikel dari halaman 5\n",
      "📄 Membuka halaman 6: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10380310&punumber=6287639&sortType=vol-only-newest&pageNumber=6\n",
      "✅ Berhasil scraping 25 artikel dari halaman 6\n",
      "📄 Membuka halaman 7: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10380310&punumber=6287639&sortType=vol-only-newest&pageNumber=7\n",
      "✅ Halaman terakhir tercapai di 6. Berhenti.\n"
     ]
    }
   ],
   "source": [
    "# List untuk menyimpan hasil scraping\n",
    "all_titles = []\n",
    "all_years = []\n",
    "all_authors = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    try:\n",
    "        base_url = row[\"URL\"]  # Pastikan kolom URL ada di dataset\n",
    "        print(f\"\\n🔍 Scraping artikel dari: {base_url}\")\n",
    "\n",
    "        page_number = 1\n",
    "        while True:\n",
    "            # Bangun URL untuk halaman tertentu\n",
    "            url = f\"{base_url}&sortType=vol-only-newest&pageNumber={page_number}\"\n",
    "            print(f\"📄 Membuka halaman {page_number}: {url}\")\n",
    "\n",
    "            driver.get(url)\n",
    "\n",
    "            # Tunggu elemen muncul untuk memastikan halaman telah dimuat\n",
    "            try:\n",
    "                WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CLASS_NAME, \"col\"))\n",
    "                )\n",
    "            except:\n",
    "                print(f\"⚠️ Halaman {page_number} gagal dimuat, lanjut ke URL berikutnya.\")\n",
    "                break\n",
    "\n",
    "            time.sleep(3)  # Beri jeda agar halaman termuat sempurna\n",
    "\n",
    "            # Parse halaman dengan BeautifulSoup\n",
    "            soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "            articles = soup.find_all(\"div\", class_=\"col result-item-align px-3\")\n",
    "\n",
    "            # Mengecek apakah artikel ditemukan\n",
    "            if not articles or len(articles) == 0:\n",
    "                print(f\"⚠️ Halaman {page_number} kosong atau tidak ditemukan artikel baru. Coba cek secara manual.\")\n",
    "                continue  # Lanjutkan ke halaman berikutnya alih-alih berhenti langsung\n",
    "\n",
    "\n",
    "            for article in articles:\n",
    "                # **Scraping Judul**\n",
    "                h2_tag = article.find(\"h2\")\n",
    "                title_tag = h2_tag.find(\"a\") if h2_tag else None\n",
    "                title = title_tag.text.strip() if title_tag else \"Judul Tidak Ditemukan\"\n",
    "                all_titles.append(title)\n",
    "\n",
    "                # **Scraping Tahun**\n",
    "                year_container = article.find(\"div\", class_=\"description text-base-md-lh\")\n",
    "                year_tag = year_container.find(\"span\") if year_container else None\n",
    "                year = year_tag.text.strip() if year_tag else \"Tahun Tidak Ditemukan\"\n",
    "                all_years.append(year)\n",
    "\n",
    "                # **Scraping Author**\n",
    "                author_spans = article.find_all(\"span\", attrs={\"_ngcontent-ng-c893371016\": True})\n",
    "                authors = \", \".join(set(span.text.strip() for span in author_spans))  # Hapus duplikasi\n",
    "                authors = authors.replace(\";\", \"\").strip(\", \")  # Bersihkan format\n",
    "                all_authors.append(authors)\n",
    "\n",
    "            print(f\"✅ Berhasil scraping {len(articles)} artikel dari halaman {page_number}\")\n",
    "\n",
    "            page_number += 1  # Lanjut ke halaman berikutnya\n",
    "\n",
    "    except KeyError as e:\n",
    "        print(f\"❌ Error: Kolom 'URL' tidak ditemukan. Pastikan nama kolom sesuai. Error: {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Terjadi kesalahan saat scraping {url}: {e}\")\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Hasil scraping telah disimpan ke: ../../data/raw/scraped_articles.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Membuat DataFrame dengan tambahan kolom author\n",
    "output_df = pd.DataFrame({\n",
    "    'Judul': all_titles,\n",
    "    'Tahun': all_years,\n",
    "    'Author': all_authors\n",
    "})\n",
    "\n",
    "# Menentukan path untuk menyimpan JSON\n",
    "output_json_path = \"../../data/raw/scraped_articles.json\"\n",
    "\n",
    "# Membuat direktori jika belum ada\n",
    "output_dir = Path(output_json_path).parent\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Menyimpan DataFrame dalam format JSON (dengan indentasi untuk keterbacaan)\n",
    "output_df.to_json(output_json_path, orient=\"records\", indent=4)\n",
    "\n",
    "print(f\"\\n✅ Hasil scraping telah disimpan ke: {output_json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Hasil scraping telah disimpan ke: ../../data/raw/scraped_articles.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Membuat DataFrame dengan tambahan kolom author\n",
    "output_df = pd.DataFrame({\n",
    "    'Judul': all_titles,\n",
    "    'Tahun': all_years,\n",
    "    'Author': all_authors\n",
    "})\n",
    "\n",
    "# Menentukan path untuk menyimpan JSON\n",
    "output_json_path = \"../../data/raw/scraped_articles.json\"\n",
    "\n",
    "# Membuat direktori jika belum ada\n",
    "output_dir = Path(output_json_path).parent\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Menyimpan DataFrame dalam format JSON (dengan indentasi untuk keterbacaan)\n",
    "output_df.to_json(output_json_path, orient=\"records\", indent=4)\n",
    "\n",
    "print(f\"\\n✅ Hasil scraping telah disimpan ke: {output_json_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
