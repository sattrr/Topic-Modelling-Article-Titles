2025-04-15 21:20:44,173 - INFO - Memulai proses scraping link artikel...
2025-04-15 21:20:44,173 - INFO - Menjalankan script: getLinks.py
2025-04-15 21:21:14,302 - INFO - Script getLinks.py selesai tanpa error.
2025-04-15 21:21:14,318 - INFO - Proses scraping link artikel selesai.
2025-04-15 21:21:39,569 - INFO - Menerima permintaan untuk streaming scraping judul dan cleaning.
2025-04-15 21:21:39,588 - INFO - Menjalankan script: getTitle.py
2025-04-15 21:21:46,831 - INFO - 2025-04-15 21:21:46,831 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8600701&punumber=6287639
2025-04-15 21:21:46,833 - INFO - 2025-04-15 21:21:46,831 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8600701&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-15 21:22:00,456 - INFO - 2025-04-15 21:22:00,456 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8600701&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-15 21:22:00,459 - INFO - 2025-04-15 21:22:00,456 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8274985&punumber=6287639
2025-04-15 21:22:00,459 - INFO - 2025-04-15 21:22:00,456 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8274985&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-15 21:22:08,421 - INFO - 2025-04-15 21:22:08,421 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8274985&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-15 21:22:08,427 - INFO - 2025-04-15 21:22:08,423 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=9668973&punumber=6287639
2025-04-15 21:22:08,430 - INFO - 2025-04-15 21:22:08,423 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=9668973&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-15 21:22:15,803 - INFO - 2025-04-15 21:22:15,803 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=9668973&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-15 21:22:15,806 - INFO - 2025-04-15 21:22:15,803 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10380310&punumber=6287639
2025-04-15 21:22:15,808 - INFO - 2025-04-15 21:22:15,805 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10380310&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-15 21:22:22,961 - INFO - 2025-04-15 21:22:22,961 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10380310&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-15 21:22:22,961 - INFO - 2025-04-15 21:22:22,961 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10820123&punumber=6287639
2025-04-15 21:22:22,961 - INFO - 2025-04-15 21:22:22,961 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10820123&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-15 21:22:29,607 - INFO - 2025-04-15 21:22:29,607 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10820123&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-15 21:22:29,611 - INFO - 2025-04-15 21:22:29,607 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639
2025-04-15 21:22:29,613 - INFO - 2025-04-15 21:22:29,607 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-15 21:22:35,965 - INFO - 2025-04-15 21:22:35,965 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-15 21:22:35,967 - INFO - 2025-04-15 21:22:35,967 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=9312710&punumber=6287639
2025-04-15 21:22:35,967 - INFO - 2025-04-15 21:22:35,967 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=9312710&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-15 21:22:41,961 - INFO - 2025-04-15 21:22:41,961 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=9312710&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-15 21:22:41,961 - INFO - 2025-04-15 21:22:41,961 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7859429&punumber=6287639
2025-04-15 21:22:41,961 - INFO - 2025-04-15 21:22:41,961 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7859429&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-15 21:22:47,575 - INFO - 2025-04-15 21:22:47,575 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7859429&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-15 21:22:47,583 - INFO - 2025-04-15 21:22:47,575 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8948470&punumber=6287639
2025-04-15 21:22:47,583 - INFO - 2025-04-15 21:22:47,575 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8948470&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-15 21:22:56,740 - INFO - 2025-04-15 21:22:56,740 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8948470&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-15 21:22:56,743 - INFO - 2025-04-15 21:22:56,740 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=6705689&punumber=6287639
2025-04-15 21:22:56,743 - INFO - 2025-04-15 21:22:56,740 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=6705689&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-15 21:23:02,008 - INFO - 2025-04-15 21:23:02,008 - WARNING - \U0001f6ab Tidak ada artikel ditemukan di halaman 1.
2025-04-15 21:23:02,008 - INFO - 2025-04-15 21:23:02,008 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=6336544&punumber=6287639
2025-04-15 21:23:02,008 - INFO - 2025-04-15 21:23:02,008 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=6336544&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-15 21:23:09,282 - INFO - 2025-04-15 21:23:09,282 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=6336544&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-15 21:23:09,282 - INFO - 2025-04-15 21:23:09,282 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7419931&punumber=6287639
2025-04-15 21:23:09,282 - INFO - 2025-04-15 21:23:09,282 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7419931&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-15 21:23:14,837 - INFO - 2025-04-15 21:23:14,835 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7419931&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-15 21:23:14,839 - INFO - 2025-04-15 21:23:14,837 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7042252&punumber=6287639
2025-04-15 21:23:14,841 - INFO - 2025-04-15 21:23:14,838 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7042252&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-15 21:23:20,853 - INFO - 2025-04-15 21:23:20,853 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7042252&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-15 21:23:28,168 - INFO - Script getTitle.py selesai.

2025-04-15 21:23:28,168 - INFO - Menjalankan script: cleaningdata.py
2025-04-15 21:23:29,969 - INFO - Traceback (most recent call last):
2025-04-15 21:23:29,970 - INFO - File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\cleaningdata.py", line 14, in <module>
2025-04-15 21:23:29,972 - INFO - df = pd.read_json(input_json_path)
2025-04-15 21:23:29,972 - INFO - ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-04-15 21:23:29,974 - INFO - File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 791, in read_json
2025-04-15 21:23:29,974 - INFO - json_reader = JsonReader(
2025-04-15 21:23:29,976 - INFO - ^^^^^^^^^^^
2025-04-15 21:23:29,977 - INFO - File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 904, in __init__
2025-04-15 21:23:29,979 - INFO - data = self._get_data_from_filepath(filepath_or_buffer)
2025-04-15 21:23:29,981 - INFO - ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-04-15 21:23:29,982 - INFO - File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 960, in _get_data_from_filepath
2025-04-15 21:23:29,985 - INFO - raise FileNotFoundError(f"File {filepath_or_buffer} does not exist")
2025-04-15 21:23:29,985 - INFO - FileNotFoundError: File ../../data/raw/scraped_articles.json does not exist
2025-04-15 21:23:30,094 - INFO - Script cleaningdata.py selesai.

2025-04-15 21:24:46,602 - INFO - Memulai proses scraping link artikel...
2025-04-15 21:24:46,605 - INFO - Menjalankan script: getLinks.py
2025-04-15 21:25:19,973 - INFO - Script getLinks.py selesai tanpa error.
2025-04-15 21:25:19,973 - INFO - Proses scraping link artikel selesai.
2025-04-15 21:26:15,294 - INFO - Memulai proses scraping link artikel...
2025-04-15 21:26:15,296 - INFO - Menjalankan script: getLinks.py
2025-04-15 21:26:45,960 - INFO - Script getLinks.py selesai tanpa error.
2025-04-15 21:26:45,976 - INFO - Proses scraping link artikel selesai.
2025-04-15 21:27:12,194 - INFO - Menerima permintaan untuk streaming scraping judul dan cleaning.
2025-04-15 21:27:12,225 - INFO - Menjalankan script: getTitle.py
2025-04-15 21:27:19,488 - INFO - 2025-04-15 21:27:19,488 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7042252&punumber=6287639
2025-04-15 21:27:19,492 - INFO - 2025-04-15 21:27:19,488 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7042252&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-15 21:27:42,924 - INFO - 2025-04-15 21:27:42,924 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7042252&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-15 21:27:42,927 - INFO - 2025-04-15 21:27:42,924 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=6336544&punumber=6287639
2025-04-15 21:27:42,930 - INFO - 2025-04-15 21:27:42,927 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=6336544&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-15 21:27:51,015 - INFO - 2025-04-15 21:27:51,015 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=6336544&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-15 21:27:51,015 - INFO - 2025-04-15 21:27:51,015 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10380310&punumber=6287639
2025-04-15 21:27:51,021 - INFO - 2025-04-15 21:27:51,015 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10380310&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-15 21:27:57,691 - INFO - 2025-04-15 21:27:57,690 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10380310&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-15 21:27:57,693 - INFO - 2025-04-15 21:27:57,691 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7859429&punumber=6287639
2025-04-15 21:27:57,695 - INFO - 2025-04-15 21:27:57,691 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7859429&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-15 21:28:04,058 - INFO - 2025-04-15 21:28:04,058 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7859429&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-15 21:28:04,060 - INFO - 2025-04-15 21:28:04,058 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=6705689&punumber=6287639
2025-04-15 21:28:04,062 - INFO - 2025-04-15 21:28:04,058 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=6705689&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-15 21:28:10,974 - INFO - 2025-04-15 21:28:10,974 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=6705689&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-15 21:28:10,976 - INFO - 2025-04-15 21:28:10,974 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=9312710&punumber=6287639
2025-04-15 21:28:10,977 - INFO - 2025-04-15 21:28:10,974 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=9312710&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-15 21:28:16,611 - INFO - 2025-04-15 21:28:16,611 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=9312710&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-15 21:28:16,613 - INFO - 2025-04-15 21:28:16,611 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7419931&punumber=6287639
2025-04-15 21:28:16,613 - INFO - 2025-04-15 21:28:16,611 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7419931&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-15 21:28:37,079 - INFO - Traceback (most recent call last):
2025-04-15 21:28:37,079 - INFO - File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 124, in <module>
2025-04-15 21:28:37,131 - INFO - scrape_titles_per_page(df, driver, OUTPUT_JSON_PATH)
2025-04-15 21:28:37,131 - INFO - File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 79, in scrape_titles_per_page
2025-04-15 21:28:37,131 - INFO - time.sleep(3)
2025-04-15 21:28:37,131 - INFO - KeyboardInterrupt
2025-04-15 21:28:41,564 - INFO - Script getTitle.py selesai.

2025-04-15 21:28:41,564 - INFO - Menjalankan script: cleaningdata.py
2025-04-15 21:28:42,857 - INFO - Traceback (most recent call last):
2025-04-15 21:28:42,862 - INFO - File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\cleaningdata.py", line 14, in <module>
2025-04-15 21:28:42,862 - INFO - df = pd.read_json(input_json_path)
2025-04-15 21:28:42,864 - INFO - ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-04-15 21:28:42,864 - INFO - File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 791, in read_json
2025-04-15 21:28:42,868 - INFO - json_reader = JsonReader(
2025-04-15 21:28:42,870 - INFO - ^^^^^^^^^^^
2025-04-15 21:28:42,870 - INFO - File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 904, in __init__
2025-04-15 21:28:42,872 - INFO - data = self._get_data_from_filepath(filepath_or_buffer)
2025-04-15 21:28:42,873 - INFO - ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
2025-04-15 21:28:42,873 - INFO - File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 960, in _get_data_from_filepath
2025-04-15 21:28:42,876 - INFO - raise FileNotFoundError(f"File {filepath_or_buffer} does not exist")
2025-04-15 21:28:42,878 - INFO - FileNotFoundError: File ../../data/raw/scraped_articles.json does not exist
2025-04-15 21:28:42,996 - INFO - Script cleaningdata.py selesai.

2025-04-15 21:55:51,265 - INFO - Menerima permintaan untuk streaming scraping judul dan cleaning.
2025-04-15 21:55:51,277 - INFO - Menjalankan script: getTitle.py
2025-04-15 21:55:55,870 - INFO - 2025-04-15 21:55:55,870 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7042252&punumber=6287639
2025-04-15 21:55:55,870 - INFO - 2025-04-15 21:55:55,870 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7042252&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-15 21:56:00,074 - INFO - 2025-04-15 21:56:00,074 - ERROR - \u26db Halaman 1 gagal dimuat. Melanjutkan ke URL berikutnya.
2025-04-15 21:58:29,837 - INFO - Menerima permintaan untuk menjalankan seluruh rangkaian proses.
2025-04-15 21:58:29,846 - INFO - Memulai seluruh rangkaian proses...
2025-04-15 21:58:29,847 - INFO - Memulai proses scraping link artikel...
2025-04-15 21:58:29,847 - INFO - Menjalankan script: getLinks.py
2025-04-15 21:58:55,803 - INFO - Script getLinks.py selesai tanpa error.
2025-04-15 21:58:55,803 - INFO - Memulai scraping judul...
2025-04-15 21:58:55,803 - INFO - Menjalankan script: getTitle.py
2025-04-15 22:00:11,496 - ERROR - Script getTitle.py gagal dijalankan.
2025-04-15 22:00:11,496 - ERROR - 2025-04-15 21:59:04,164 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10820123&punumber=6287639
2025-04-15 21:59:04,164 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10820123&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-15 21:59:23,792 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10820123&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-15 21:59:23,794 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=6705689&punumber=6287639
2025-04-15 21:59:23,794 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=6705689&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-15 21:59:31,558 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=6705689&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-15 21:59:31,558 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7042252&punumber=6287639
2025-04-15 21:59:31,559 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7042252&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-15 21:59:46,512 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7042252&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-15 21:59:46,513 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7859429&punumber=6287639
2025-04-15 21:59:46,513 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7859429&punumber=6287639&sortType=vol-only-newest&pageNumber=1
Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 124, in <module>
    scrape_titles_per_page(df, driver, OUTPUT_JSON_PATH)
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 79, in scrape_titles_per_page
    time.sleep(3)
KeyboardInterrupt

2025-04-15 22:00:11,508 - INFO - Memulai proses cleaning data...
2025-04-15 22:00:11,508 - INFO - Menjalankan script: cleaningdata.py
2025-04-15 22:00:14,387 - ERROR - Script cleaningdata.py gagal dijalankan.
2025-04-15 22:00:14,403 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\cleaningdata.py", line 1, in <module>
    import pandas as pd
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\__init__.py", line 155, in <module>
    from pandas.io.api import (
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\api.py", line 16, in <module>
    from pandas.io.parquet import read_parquet
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1026, in get_code
  File "<frozen importlib._bootstrap_external>", line 1148, in path_stats
  File "<frozen importlib._bootstrap_external>", line 147, in _path_stat
KeyboardInterrupt

2025-04-15 22:00:14,403 - INFO - Scraping judul dan cleaning data selesai.
2025-04-15 22:00:14,403 - INFO - Seluruh proses selesai.
2025-04-15 22:24:33,985 - INFO - Memulai proses scraping link artikel...
2025-04-15 22:24:33,993 - INFO - Menjalankan script: getLinks.py
2025-04-15 22:25:03,282 - ERROR - Script getLinks.py gagal dijalankan.
2025-04-15 22:25:03,282 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 1374, in getresponse
    response.begin()
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 318, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 279, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\socket.py", line 706, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 40, in scrape_ieee_links
    driver.get(target_url)
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 454, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 427, in execute
    response = self.command_executor.execute(driver_command, params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 404, in execute
    return self._request(command_info[0], url, body=data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 428, in _request
    response = self._conn.request(method, url, body=body, headers=headers, timeout=self._client_config.timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 534, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connection.py", line 516, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 1376, in getresponse
    self.close()
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connection.py", line 320, in close
    def close(self) -> None:

KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\util\connection.py", line 73, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 71, in <module>
    scrape_ieee_links()
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 68, in scrape_ieee_links
    driver.quit()
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\chromium\webdriver.py", line 188, in quit
    super().quit()
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 589, in quit
    self.execute(Command.QUIT)
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 427, in execute
    response = self.command_executor.execute(driver_command, params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 404, in execute
    return self._request(command_info[0], url, body=data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\remote_connection.py", line 428, in _request
    response = self._conn.request(method, url, body=body, headers=headers, timeout=self._client_config.timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\_request_methods.py", line 135, in request
    return self.request_encode_url(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\_request_methods.py", line 182, in request_encode_url
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 787, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connectionpool.py", line 493, in _make_request
    conn.request(
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connection.py", line 445, in request
    self.endheaders()
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 975, in send
    self.connect()
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connection.py", line 276, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\connection.py", line 198, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\urllib3\util\connection.py", line 81, in create_connection
    sock.close()
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\socket.py", line 499, in close
    def close(self):

KeyboardInterrupt

2025-04-15 22:25:03,291 - INFO - Proses scraping link artikel selesai.
2025-04-15 22:25:35,132 - INFO - Menerima permintaan untuk menjalankan seluruh rangkaian proses.
2025-04-15 22:25:35,183 - INFO - Memulai seluruh rangkaian proses...
2025-04-15 22:25:35,185 - INFO - Memulai proses scraping link artikel...
2025-04-15 22:25:35,189 - INFO - Menjalankan script: getLinks.py
2025-04-15 22:25:40,547 - ERROR - Script getLinks.py gagal dijalankan.
2025-04-15 22:25:40,547 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 71, in <module>
    scrape_ieee_links()
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 37, in scrape_ieee_links
    driver = setup_driver()
             ^^^^^^^^^^^^^^
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 20, in setup_driver
    service = Service(ChromeDriverManager().install())
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\chrome.py", line 40, in install
    driver_path = self._get_driver_binary_path(self.driver)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\core\manager.py", line 35, in _get_driver_binary_path
    binary_path = self._cache_manager.find_driver(driver)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\core\driver_cache.py", line 103, in find_driver
    browser_version = self._os_system_manager.get_browser_version_from_os(browser_type)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\core\os_manager.py", line 159, in get_browser_version_from_os
    version = read_version_from_cmd(cmd_mapping, pattern)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\core\utils.py", line 46, in read_version_from_cmd
    stdout = stream.communicate()[0].decode()
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\subprocess.py", line 1194, in communicate
    stdout = self.stdout.read()
             ^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

2025-04-15 22:25:40,563 - INFO - Memulai scraping judul...
2025-04-15 22:25:40,563 - INFO - Menjalankan script: getTitle.py
2025-04-15 22:25:43,131 - ERROR - Script getTitle.py gagal dijalankan.
2025-04-15 22:25:43,131 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 121, in <module>
    driver = setup_driver()
             ^^^^^^^^^^^^^^
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 29, in setup_driver
    service = Service(ChromeDriverManager().install())
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\chrome.py", line 40, in install
    driver_path = self._get_driver_binary_path(self.driver)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\core\manager.py", line 35, in _get_driver_binary_path
    binary_path = self._cache_manager.find_driver(driver)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\core\driver_cache.py", line 103, in find_driver
    browser_version = self._os_system_manager.get_browser_version_from_os(browser_type)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\core\os_manager.py", line 147, in get_browser_version_from_os
    OSType.WIN: windows_browser_apps_to_cmd(
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\core\utils.py", line 28, in windows_browser_apps_to_cmd
    powershell = determine_powershell()
                 ^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\core\utils.py", line 62, in determine_powershell
    stdout = stream.communicate()[0].decode()
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\subprocess.py", line 1194, in communicate
    stdout = self.stdout.read()
             ^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

2025-04-15 22:25:43,131 - INFO - Memulai proses cleaning data...
2025-04-15 22:25:43,131 - INFO - Menjalankan script: cleaningdata.py
2025-04-15 22:25:44,299 - ERROR - Script cleaningdata.py gagal dijalankan.
2025-04-15 22:25:44,299 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\cleaningdata.py", line 1, in <module>
    import pandas as pd
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\__init__.py", line 62, in <module>
    from pandas.core.api import (
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\api.py", line 47, in <module>
    from pandas.core.groupby import (
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\groupby\__init__.py", line 1, in <module>
    from pandas.core.groupby.generic import (
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\groupby\generic.py", line 68, in <module>
    from pandas.core.frame import DataFrame
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\frame.py", line 149, in <module>
    from pandas.core.generic import (
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\generic.py", line 184, in <module>
    from pandas.core.methods.describe import describe_ndframe
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\methods\describe.py", line 41, in <module>
    from pandas.io.formats.format import format_percentiles
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\formats\format.py", line 82, in <module>
    from pandas.io.common import (
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\common.py", line 17, in <module>
    import gzip
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1069, in get_code
  File "<frozen importlib._bootstrap_external>", line 729, in _compile_bytecode
KeyboardInterrupt

2025-04-15 22:25:44,299 - INFO - Scraping judul dan cleaning data selesai.
2025-04-15 22:25:44,299 - INFO - Seluruh proses selesai.
2025-04-15 23:55:03,602 - INFO - Menerima permintaan untuk menjalankan seluruh rangkaian proses.
2025-04-15 23:55:03,623 - INFO - Memulai seluruh rangkaian proses...
2025-04-15 23:55:03,623 - INFO - Memulai proses scraping link artikel...
2025-04-15 23:55:03,623 - INFO - Menjalankan script: getLinks.py
2025-04-15 23:55:08,720 - ERROR - Script getLinks.py gagal dijalankan.
2025-04-15 23:55:08,720 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 71, in <module>
    scrape_ieee_links()
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 37, in scrape_ieee_links
    driver = setup_driver()
             ^^^^^^^^^^^^^^
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 20, in setup_driver
    service = Service(ChromeDriverManager().install())
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\chrome.py", line 40, in install
    driver_path = self._get_driver_binary_path(self.driver)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\core\manager.py", line 35, in _get_driver_binary_path
    binary_path = self._cache_manager.find_driver(driver)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\core\driver_cache.py", line 103, in find_driver
    browser_version = self._os_system_manager.get_browser_version_from_os(browser_type)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\core\os_manager.py", line 159, in get_browser_version_from_os
    version = read_version_from_cmd(cmd_mapping, pattern)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\core\utils.py", line 46, in read_version_from_cmd
    stdout = stream.communicate()[0].decode()
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\subprocess.py", line 1194, in communicate
    stdout = self.stdout.read()
             ^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

2025-04-15 23:55:08,720 - INFO - Memulai scraping judul...
2025-04-15 23:55:08,720 - INFO - Menjalankan script: getTitle.py
2025-04-15 23:55:09,716 - ERROR - Script getTitle.py gagal dijalankan.
2025-04-15 23:55:09,718 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 1, in <module>
    import pandas as pd
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\__init__.py", line 62, in <module>
    from pandas.core.api import (
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\api.py", line 47, in <module>
    from pandas.core.groupby import (
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\groupby\__init__.py", line 1, in <module>
    from pandas.core.groupby.generic import (
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\groupby\generic.py", line 68, in <module>
    from pandas.core.frame import DataFrame
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1069, in get_code
  File "<frozen importlib._bootstrap_external>", line 729, in _compile_bytecode
KeyboardInterrupt

2025-04-15 23:55:09,718 - INFO - Memulai proses cleaning data...
2025-04-15 23:55:09,720 - INFO - Menjalankan script: cleaningdata.py
2025-04-15 23:55:10,644 - ERROR - Script cleaningdata.py gagal dijalankan.
2025-04-15 23:55:10,644 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\cleaningdata.py", line 1, in <module>
    import pandas as pd
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\__init__.py", line 62, in <module>
    from pandas.core.api import (
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\api.py", line 28, in <module>
    from pandas.core.arrays import Categorical
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\arrays\__init__.py", line 19, in <module>
    from pandas.core.arrays.sparse import SparseArray
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\arrays\sparse\__init__.py", line 1, in <module>
    from pandas.core.arrays.sparse.accessor import (
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\arrays\sparse\accessor.py", line 17, in <module>
    from pandas.core.arrays.sparse.array import SparseArray
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\arrays\sparse\array.py", line 84, in <module>
    from pandas.io.formats import printing
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1069, in get_code
  File "<frozen importlib._bootstrap_external>", line 729, in _compile_bytecode
KeyboardInterrupt

2025-04-15 23:55:10,644 - INFO - Scraping judul dan cleaning data selesai.
2025-04-15 23:55:10,644 - INFO - Seluruh proses selesai.
2025-04-15 23:57:01,248 - INFO - Menerima permintaan untuk menjalankan seluruh rangkaian proses.
2025-04-15 23:57:01,266 - INFO - Memulai seluruh rangkaian proses...
2025-04-15 23:57:01,268 - INFO - Memulai proses scraping link artikel...
2025-04-15 23:57:01,268 - INFO - Menjalankan script: getLinks.py
2025-04-15 23:57:03,855 - ERROR - Script getLinks.py gagal dijalankan.
2025-04-15 23:57:03,855 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 5, in <module>
    from selenium import webdriver
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\__init__.py", line 20, in <module>
    from .chrome.webdriver import WebDriver as Chrome  # noqa
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\chrome\webdriver.py", line 18, in <module>
    from selenium.webdriver.chromium.webdriver import ChromiumDriver
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\chromium\webdriver.py", line 22, in <module>
    from selenium.webdriver.remote.webdriver import WebDriver as RemoteWebDriver
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\webdriver.py", line 72, in <module>
    from .websocket_connection import WebSocketConnection
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\remote\websocket_connection.py", line 23, in <module>
    from websocket import WebSocketApp  # type: ignore
    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\websocket\__init__.py", line 19, in <module>
    from ._abnf import *
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\websocket\_abnf.py", line 9, in <module>
    from ._utils import validate_utf8
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\websocket\_utils.py", line 35, in <module>
    from wsaccel.utf8validator import Utf8Validator
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1140, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 1080, in _find_spec
  File "<frozen importlib._bootstrap_external>", line 1504, in find_spec
  File "<frozen importlib._bootstrap_external>", line 1476, in _get_spec
  File "<frozen importlib._bootstrap_external>", line 1640, in find_spec
  File "<frozen importlib._bootstrap_external>", line 123, in _path_join
KeyboardInterrupt

2025-04-15 23:57:03,855 - INFO - Memulai scraping judul...
2025-04-15 23:57:03,855 - INFO - Menjalankan script: getTitle.py
2025-04-15 23:57:08,694 - ERROR - Script getTitle.py gagal dijalankan.
2025-04-15 23:57:08,696 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 121, in <module>
    driver = setup_driver()
             ^^^^^^^^^^^^^^
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 29, in setup_driver
    service = Service(ChromeDriverManager().install())
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\chrome.py", line 40, in install
    driver_path = self._get_driver_binary_path(self.driver)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\core\manager.py", line 35, in _get_driver_binary_path
    binary_path = self._cache_manager.find_driver(driver)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\core\driver_cache.py", line 103, in find_driver
    browser_version = self._os_system_manager.get_browser_version_from_os(browser_type)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\core\os_manager.py", line 159, in get_browser_version_from_os
    version = read_version_from_cmd(cmd_mapping, pattern)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\core\utils.py", line 46, in read_version_from_cmd
    stdout = stream.communicate()[0].decode()
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\subprocess.py", line 1194, in communicate
    stdout = self.stdout.read()
             ^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

2025-04-15 23:57:08,696 - INFO - Memulai proses cleaning data...
2025-04-15 23:57:08,696 - INFO - Menjalankan script: cleaningdata.py
2025-04-15 23:57:09,602 - ERROR - Script cleaningdata.py gagal dijalankan.
2025-04-15 23:57:09,602 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\cleaningdata.py", line 1, in <module>
    import pandas as pd
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\__init__.py", line 27, in <module>
    __import__(_dependency)
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\__init__.py", line 194, in <module>
    from . import lib
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\__init__.py", line 23, in <module>
    from . import _index_tricks_impl
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\lib\_index_tricks_impl.py", line 12, in <module>
    import numpy.matrixlib as matrixlib
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\matrixlib\__init__.py", line 4, in <module>
    from . import defmatrix
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\matrixlib\defmatrix.py", line 12, in <module>
    from numpy.linalg import matrix_power
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\linalg\__init__.py", line 88, in <module>
    from . import _linalg
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\linalg\_linalg.py", line 41, in <module>
    from numpy._typing import NDArray
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\_typing\__init__.py", line 102, in <module>
    from ._dtype_like import (
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\numpy\_typing\_dtype_like.py", line 193, in <module>
    type[complex]
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\typing.py", line 1352, in __or__
    return Union[self, right]
           ~~~~~^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\typing.py", line 341, in inner
    return cached(*args, **kwds)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\typing.py", line 460, in __getitem__
    return self._getitem(self, parameters)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\typing.py", line 673, in Union
    return _UnionGenericAlias(self, parameters)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\typing.py", line 1337, in __init__
    self.__parameters__ = _collect_parameters(args)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\typing.py", line 256, in _collect_parameters
    if hasattr(t, '__typing_subst__'):
       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

2025-04-15 23:57:09,602 - INFO - Scraping judul dan cleaning data selesai.
2025-04-15 23:57:09,614 - INFO - Seluruh proses selesai.
<<<<<<< HEAD
2025-04-16 08:07:50,454 - INFO - Menerima permintaan untuk menjalankan seluruh rangkaian proses.
2025-04-16 08:07:50,537 - INFO - Memulai seluruh rangkaian proses...
2025-04-16 08:07:50,537 - INFO - Memulai proses scraping link artikel...
2025-04-16 08:07:50,542 - INFO - Menjalankan script: getLinks.py
2025-04-16 08:08:15,634 - ERROR - Script getLinks.py gagal dijalankan.
2025-04-16 08:08:15,641 - ERROR - Traceback (most recent call last):
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\connection.py", line 199, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\util\connection.py", line 60, in create_connection
    for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\socket.py", line 962, in getaddrinfo
    for res in _socket.getaddrinfo(host, port, family, type, proto, flags):
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
socket.gaierror: [Errno 11001] getaddrinfo failed

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Satriock\Documents\Code\AI\MLOps\Topic Modelling\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 71, in <module>
    scrape_ieee_links()
  File "C:\Users\Satriock\Documents\Code\AI\MLOps\Topic Modelling\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 37, in scrape_ieee_links
    driver = setup_driver()
             ^^^^^^^^^^^^^^
  File "C:\Users\Satriock\Documents\Code\AI\MLOps\Topic Modelling\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 20, in setup_driver
    service = Service(ChromeDriverManager().install())
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\chrome.py", line 40, in install
    driver_path = self._get_driver_binary_path(self.driver)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\core\manager.py", line 35, in _get_driver_binary_path
    binary_path = self._cache_manager.find_driver(driver)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\core\driver_cache.py", line 107, in find_driver
    driver_version = self.get_cache_key_driver_version(driver)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\core\driver_cache.py", line 154, in get_cache_key_driver_version
    return driver.get_driver_version_to_download()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\core\driver.py", line 48, in get_driver_version_to_download
    return self.get_latest_release_version()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\drivers\chrome.py", line 59, in get_latest_release_version
    response = self._http_client.get(url)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\core\http.py", line 32, in get
    resp = requests.get(
           ^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\requests\adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\connectionpool.py", line 789, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\connectionpool.py", line 466, in _make_request
    self._validate_conn(conn)
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\connectionpool.py", line 1095, in _validate_conn
    conn.connect()
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\connection.py", line 693, in connect
    self.sock = sock = self._new_conn()
                       ^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\connection.py", line 206, in _new_conn
    raise NameResolutionError(self.host, self, e) from e
                              ^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\connection.py", line 164, in host
    @property

KeyboardInterrupt

2025-04-16 08:08:15,650 - INFO - Memulai scraping judul...
2025-04-16 08:08:15,652 - INFO - Menjalankan script: getTitle.py
2025-04-16 08:08:30,690 - ERROR - Script getTitle.py gagal dijalankan.
2025-04-16 08:08:30,691 - ERROR - Traceback (most recent call last):
  File "C:\Users\Satriock\Documents\Code\AI\MLOps\Topic Modelling\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 121, in <module>
    driver = setup_driver()
             ^^^^^^^^^^^^^^
  File "C:\Users\Satriock\Documents\Code\AI\MLOps\Topic Modelling\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 29, in setup_driver
    service = Service(ChromeDriverManager().install())
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\chrome.py", line 40, in install
    driver_path = self._get_driver_binary_path(self.driver)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\core\manager.py", line 35, in _get_driver_binary_path
    binary_path = self._cache_manager.find_driver(driver)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\core\driver_cache.py", line 107, in find_driver
    driver_version = self.get_cache_key_driver_version(driver)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\core\driver_cache.py", line 154, in get_cache_key_driver_version
    return driver.get_driver_version_to_download()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\core\driver.py", line 48, in get_driver_version_to_download
    return self.get_latest_release_version()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\drivers\chrome.py", line 59, in get_latest_release_version
    response = self._http_client.get(url)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\core\http.py", line 32, in get
    resp = requests.get(
           ^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\requests\adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\connectionpool.py", line 789, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\connectionpool.py", line 466, in _make_request
    self._validate_conn(conn)
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\connectionpool.py", line 1095, in _validate_conn
    conn.connect()
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\connection.py", line 730, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\connection.py", line 909, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\util\ssl_.py", line 469, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\util\ssl_.py", line 513, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\ssl.py", line 517, in wrap_socket
    return self.sslsocket_class._create(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\ssl.py", line 1104, in _create
    self.do_handshake()
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\ssl.py", line 1382, in do_handshake
    self._sslobj.do_handshake()
KeyboardInterrupt

2025-04-16 08:08:30,695 - INFO - Memulai proses cleaning data...
2025-04-16 08:08:30,696 - INFO - Menjalankan script: cleaningdata.py
2025-04-16 08:08:31,817 - ERROR - Script cleaningdata.py gagal dijalankan.
2025-04-16 08:08:31,817 - ERROR - Traceback (most recent call last):
  File "C:\Users\Satriock\Documents\Code\AI\MLOps\Topic Modelling\Topic-Modelling-Article-Titles\src\scrapping\cleaningdata.py", line 14, in <module>
    df = pd.read_json(input_json_path)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\io\json\_json.py", line 780, in read_json
    json_reader = JsonReader(
                  ^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\io\json\_json.py", line 893, in __init__
    data = self._get_data_from_filepath(filepath_or_buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\io\json\_json.py", line 949, in _get_data_from_filepath
    raise FileNotFoundError(f"File {filepath_or_buffer} does not exist")
FileNotFoundError: File ../../data/raw/scraped_articles.json does not exist

2025-04-16 08:08:31,822 - INFO - Scraping judul dan cleaning data selesai.
2025-04-16 08:08:31,823 - INFO - Seluruh proses selesai.
2025-04-16 08:17:04,571 - INFO - Menerima permintaan untuk menjalankan seluruh rangkaian proses.
2025-04-16 08:17:04,615 - INFO - Memulai seluruh rangkaian proses...
2025-04-16 08:17:04,618 - INFO - Memulai proses scraping link artikel...
2025-04-16 08:17:04,619 - INFO - Menjalankan script: getLinks.py
2025-04-16 08:17:32,500 - ERROR - Script getLinks.py gagal dijalankan.
2025-04-16 08:17:32,504 - ERROR - Traceback (most recent call last):
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\http\client.py", line 1395, in getresponse
    response.begin()
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\http\client.py", line 325, in begin
    version, status, reason = self._read_status()
                              ^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\http\client.py", line 286, in _read_status
    line = str(self.fp.readline(_MAXLINE + 1), "iso-8859-1")
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\socket.py", line 706, in readinto
    return self._sock.recv_into(b)
           ^^^^^^^^^^^^^^^^^^^^^^^
ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Satriock\Documents\Code\AI\MLOps\Topic Modelling\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 40, in scrape_ieee_links
    driver.get(target_url)
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\selenium\webdriver\remote\webdriver.py", line 454, in get
    self.execute(Command.GET, {"url": url})
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\selenium\webdriver\remote\webdriver.py", line 427, in execute
    response = self.command_executor.execute(driver_command, params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\selenium\webdriver\remote\remote_connection.py", line 404, in execute
    return self._request(command_info[0], url, body=data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\selenium\webdriver\remote\remote_connection.py", line 428, in _request
    response = self._conn.request(method, url, body=body, headers=headers, timeout=self._client_config.timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\_request_methods.py", line 143, in request
    return self.request_encode_body(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\_request_methods.py", line 278, in request_encode_body
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\connectionpool.py", line 789, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\connectionpool.py", line 536, in _make_request
    response = conn.getresponse()
               ^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\connection.py", line 507, in getresponse
    httplib_response = super().getresponse()
                       ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\http\client.py", line 1397, in getresponse
    self.close()
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\connection.py", line 316, in close
    def close(self) -> None:

=======
2025-04-16 08:30:14,887 - INFO - Menerima permintaan untuk menjalankan seluruh rangkaian proses.
2025-04-16 08:30:14,905 - INFO - Memulai seluruh rangkaian proses...
2025-04-16 08:30:14,905 - INFO - Memulai proses scraping link artikel...
2025-04-16 08:30:14,905 - INFO - Menjalankan script: getLinks.py
2025-04-16 08:30:20,648 - ERROR - Script getLinks.py gagal dijalankan.
2025-04-16 08:30:20,648 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 71, in <module>
    scrape_ieee_links()
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 37, in scrape_ieee_links
    driver = setup_driver()
             ^^^^^^^^^^^^^^
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 20, in setup_driver
    service = Service(ChromeDriverManager().install())
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\chrome.py", line 40, in install
    driver_path = self._get_driver_binary_path(self.driver)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\core\manager.py", line 35, in _get_driver_binary_path
    binary_path = self._cache_manager.find_driver(driver)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\core\driver_cache.py", line 103, in find_driver
    browser_version = self._os_system_manager.get_browser_version_from_os(browser_type)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\core\os_manager.py", line 159, in get_browser_version_from_os
    version = read_version_from_cmd(cmd_mapping, pattern)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\webdriver_manager\core\utils.py", line 46, in read_version_from_cmd
    stdout = stream.communicate()[0].decode()
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\subprocess.py", line 1194, in communicate
    stdout = self.stdout.read()
             ^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

2025-04-16 08:30:20,649 - INFO - Memulai scraping judul...
2025-04-16 08:30:20,649 - INFO - Menjalankan script: getTitle.py
2025-04-16 08:30:21,287 - ERROR - Script getTitle.py gagal dijalankan.
2025-04-16 08:30:21,287 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 1, in <module>
    import pandas as pd
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\__init__.py", line 62, in <module>
    from pandas.core.api import (
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\api.py", line 47, in <module>
    from pandas.core.groupby import (
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\groupby\__init__.py", line 1, in <module>
    from pandas.core.groupby.generic import (
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\groupby\generic.py", line 69, in <module>
    from pandas.core.groupby import (
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\groupby\ops.py", line 25, in <module>
    import pandas._libs.groupby as libgroupby
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1140, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 1080, in _find_spec
  File "<frozen importlib._bootstrap_external>", line 1504, in find_spec
  File "<frozen importlib._bootstrap_external>", line 1476, in _get_spec
  File "<frozen importlib._bootstrap_external>", line 1612, in find_spec
  File "<frozen importlib._bootstrap_external>", line 147, in _path_stat
KeyboardInterrupt

2025-04-16 08:30:21,287 - INFO - Memulai proses cleaning data...
2025-04-16 08:30:21,287 - INFO - Menjalankan script: cleaningdata.py
2025-04-16 08:30:21,932 - ERROR - Script cleaningdata.py gagal dijalankan.
2025-04-16 08:30:21,932 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\cleaningdata.py", line 1, in <module>
    import pandas as pd
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\__init__.py", line 62, in <module>
    from pandas.core.api import (
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\api.py", line 47, in <module>
    from pandas.core.groupby import (
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\groupby\__init__.py", line 1, in <module>
    from pandas.core.groupby.generic import (
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\groupby\generic.py", line 68, in <module>
    from pandas.core.frame import DataFrame
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\frame.py", line 149, in <module>
    from pandas.core.generic import (
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\generic.py", line 184, in <module>
    from pandas.core.methods.describe import describe_ndframe
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\methods\describe.py", line 41, in <module>
    from pandas.io.formats.format import format_percentiles
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\formats\format.py", line 82, in <module>
    from pandas.io.common import (
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\common.py", line 28, in <module>
    from pathlib import Path
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\pathlib.py", line 14, in <module>
    from urllib.parse import quote_from_bytes as urlquote_from_bytes
  File "<frozen importlib._bootstrap>", line 1178, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1149, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1032, in get_code
  File "<frozen importlib._bootstrap_external>", line 1131, in get_data
KeyboardInterrupt

2025-04-16 08:30:21,932 - INFO - Scraping judul dan cleaning data selesai.
2025-04-16 08:30:21,932 - INFO - Seluruh proses selesai.
2025-04-16 08:41:01,968 - INFO - Menerima permintaan untuk menjalankan seluruh rangkaian proses.
2025-04-16 08:41:01,976 - INFO - Memulai seluruh rangkaian proses...
2025-04-16 08:41:01,976 - INFO - Memulai proses scraping link artikel...
2025-04-16 08:41:01,976 - INFO - Menjalankan script: getLinks.py
2025-04-16 08:41:02,986 - INFO - Script getLinks.py selesai tanpa error.
2025-04-16 08:41:02,986 - INFO - Memulai scraping judul...
2025-04-16 08:41:02,998 - INFO - Menjalankan script: getTitle.py
2025-04-16 08:41:04,326 - ERROR - Script getTitle.py gagal dijalankan.
2025-04-16 08:41:04,326 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\common\driver_finder.py", line 64, in _binary_paths
    raise ValueError(f"The path is not a valid file: {path}")
ValueError: The path is not a valid file: /usr/bin/chromedriver

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 121, in <module>
    driver = setup_driver()
             ^^^^^^^^^^^^^^
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 38, in setup_driver
    return webdriver.Chrome(service=service, options=options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\chrome\webdriver.py", line 45, in __init__
    super().__init__(
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\chromium\webdriver.py", line 50, in __init__
    if finder.get_browser_path():
       ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\common\driver_finder.py", line 47, in get_browser_path
    return self._binary_paths()["browser_path"]
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\common\driver_finder.py", line 78, in _binary_paths
    raise NoSuchDriverException(msg) from err
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location


2025-04-16 08:41:04,326 - INFO - Memulai proses cleaning data...
2025-04-16 08:41:04,326 - INFO - Menjalankan script: cleaningdata.py
2025-04-16 08:41:05,031 - ERROR - Script cleaningdata.py gagal dijalankan.
2025-04-16 08:41:05,031 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\cleaningdata.py", line 14, in <module>
    df = pd.read_json(input_json_path)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 791, in read_json
    json_reader = JsonReader(
                  ^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 904, in __init__
    data = self._get_data_from_filepath(filepath_or_buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 960, in _get_data_from_filepath
    raise FileNotFoundError(f"File {filepath_or_buffer} does not exist")
FileNotFoundError: File ../../data/raw/scraped_articles.json does not exist

2025-04-16 08:41:05,031 - INFO - Scraping judul dan cleaning data selesai.
2025-04-16 08:41:05,031 - INFO - Seluruh proses selesai.
2025-04-16 08:42:07,726 - INFO - Menerima permintaan untuk menjalankan seluruh rangkaian proses.
2025-04-16 08:42:07,740 - INFO - Memulai seluruh rangkaian proses...
2025-04-16 08:42:07,740 - INFO - Memulai proses scraping link artikel...
2025-04-16 08:42:07,741 - INFO - Menjalankan script: getLinks.py
2025-04-16 08:42:30,172 - INFO - Script getLinks.py selesai tanpa error.
2025-04-16 08:42:30,172 - INFO - Memulai scraping judul...
2025-04-16 08:42:30,173 - INFO - Menjalankan script: getTitle.py
2025-04-16 08:43:31,692 - ERROR - Script getTitle.py gagal dijalankan.
2025-04-16 08:43:31,692 - ERROR - 2025-04-16 08:42:33,954 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8948470&punumber=6287639
2025-04-16 08:42:33,954 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8948470&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-16 08:42:39,704 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8948470&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-16 08:42:39,711 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7419931&punumber=6287639
2025-04-16 08:42:39,711 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7419931&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-16 08:42:44,845 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7419931&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-16 08:42:44,845 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639
2025-04-16 08:42:44,845 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-16 08:42:50,257 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-16 08:42:50,257 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=9312710&punumber=6287639
2025-04-16 08:42:50,257 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=9312710&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-16 08:42:54,433 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=9312710&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-16 08:42:54,433 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8600701&punumber=6287639
2025-04-16 08:42:54,433 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8600701&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-16 08:42:58,652 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8600701&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-16 08:42:58,653 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8274985&punumber=6287639
2025-04-16 08:42:58,653 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8274985&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-16 08:43:03,310 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8274985&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-16 08:43:03,311 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10820123&punumber=6287639
2025-04-16 08:43:03,311 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10820123&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-16 08:43:07,571 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10820123&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-16 08:43:07,571 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7042252&punumber=6287639
2025-04-16 08:43:07,571 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7042252&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-16 08:43:11,777 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7042252&punumber=6287639: 'charmap' codec can't encode character '\u2705' in position 0: character maps to <undefined>
2025-04-16 08:43:11,777 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=9668973&punumber=6287639
2025-04-16 08:43:11,777 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=9668973&punumber=6287639&sortType=vol-only-newest&pageNumber=1
Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 124, in <module>
    scrape_titles_per_page(df, driver, OUTPUT_JSON_PATH)
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 79, in scrape_titles_per_page
    time.sleep(3)
>>>>>>> abiyyu-v-crawling
KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
<<<<<<< HEAD
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\util\connection.py", line 73, in create_connection
=======
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\socket.py", line 836, in create_connection
>>>>>>> abiyyu-v-crawling
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
<<<<<<< HEAD
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\selenium\webdriver\chromium\webdriver.py", line 188, in quit
    super().quit()
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\selenium\webdriver\remote\webdriver.py", line 589, in quit
    self.execute(Command.QUIT)
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\selenium\webdriver\remote\webdriver.py", line 427, in execute
    response = self.command_executor.execute(driver_command, params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\selenium\webdriver\remote\remote_connection.py", line 404, in execute
    return self._request(command_info[0], url, body=data)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\selenium\webdriver\remote\remote_connection.py", line 428, in _request
    response = self._conn.request(method, url, body=body, headers=headers, timeout=self._client_config.timeout)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\_request_methods.py", line 135, in request
    return self.request_encode_url(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\_request_methods.py", line 182, in request_encode_url
    return self.urlopen(method, url, **extra_kw)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\poolmanager.py", line 443, in urlopen
    response = conn.urlopen(method, u.request_uri, **kw)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\connectionpool.py", line 789, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\connectionpool.py", line 495, in _make_request
    conn.request(
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\connection.py", line 441, in request
    self.endheaders()
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\http\client.py", line 1298, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\http\client.py", line 1058, in _send_output
    self.send(msg)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\http\client.py", line 996, in send
    self.connect()
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\connection.py", line 279, in connect
    self.sock = self._new_conn()
                ^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\connection.py", line 199, in _new_conn
    sock = connection.create_connection(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\util\connection.py", line 81, in create_connection
    sock.close()
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\socket.py", line 499, in close
    def close(self):

KeyboardInterrupt

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\socket.py", line 836, in create_connection
    sock.connect(sa)
ConnectionRefusedError: [WinError 10061] No connection could be made because the target machine actively refused it

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Satriock\Documents\Code\AI\MLOps\Topic Modelling\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 71, in <module>
    scrape_ieee_links()
  File "C:\Users\Satriock\Documents\Code\AI\MLOps\Topic Modelling\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 68, in scrape_ieee_links
    driver.quit()
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\selenium\webdriver\chromium\webdriver.py", line 193, in quit
    self.service.stop()
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\selenium\webdriver\common\service.py", line 157, in stop
    self.send_remote_shutdown_command()
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\selenium\webdriver\common\service.py", line 137, in send_remote_shutdown_command
    request.urlopen(f"{self.service_url}/shutdown")
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\urllib\request.py", line 216, in urlopen
    return opener.open(url, data, timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\urllib\request.py", line 519, in open
    response = self._open(req, data)
               ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\urllib\request.py", line 536, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\urllib\request.py", line 496, in _call_chain
    result = func(*args)
             ^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\urllib\request.py", line 1377, in http_open
    return self.do_open(http.client.HTTPConnection, req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\urllib\request.py", line 1348, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\http\client.py", line 1303, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\http\client.py", line 1349, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\http\client.py", line 1298, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\http\client.py", line 1058, in _send_output
    self.send(msg)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\http\client.py", line 996, in send
    self.connect()
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\http\client.py", line 962, in connect
    self.sock = self._create_connection(
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\socket.py", line 843, in create_connection
=======
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 126, in <module>
    driver.quit()
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\chromium\webdriver.py", line 193, in quit
    self.service.stop()
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\common\service.py", line 157, in stop
    self.send_remote_shutdown_command()
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\common\service.py", line 137, in send_remote_shutdown_command
    request.urlopen(f"{self.service_url}/shutdown")
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\urllib\request.py", line 216, in urlopen
    return opener.open(url, data, timeout)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\urllib\request.py", line 519, in open
    response = self._open(req, data)
               ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\urllib\request.py", line 536, in _open
    result = self._call_chain(self.handle_open, protocol, protocol +
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\urllib\request.py", line 496, in _call_chain
    result = func(*args)
             ^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\urllib\request.py", line 1377, in http_open
    return self.do_open(http.client.HTTPConnection, req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\urllib\request.py", line 1348, in do_open
    h.request(req.get_method(), req.selector, req.data, headers,
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 1282, in request
    self._send_request(method, url, body, headers, encode_chunked)
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 1328, in _send_request
    self.endheaders(body, encode_chunked=encode_chunked)
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 1277, in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 1037, in _send_output
    self.send(msg)
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 975, in send
    self.connect()
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\http\client.py", line 941, in connect
    self.sock = self._create_connection(
                ^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\socket.py", line 843, in create_connection
>>>>>>> abiyyu-v-crawling
    exceptions.clear()  # raise only the last error
    ^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

<<<<<<< HEAD
2025-04-16 08:17:32,516 - INFO - Memulai scraping judul...
2025-04-16 08:17:32,517 - INFO - Menjalankan script: getTitle.py
2025-04-16 08:17:51,988 - ERROR - Script getTitle.py gagal dijalankan.
2025-04-16 08:17:51,995 - ERROR - 2025-04-16 08:17:39,691 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10820123&punumber=6287639
2025-04-16 08:17:39,691 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10820123&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-16 08:17:47,711 - ERROR - \u26db Halaman 1 gagal dimuat. Melanjutkan ke URL berikutnya.
2025-04-16 08:17:47,712 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=6705689&punumber=6287639
2025-04-16 08:17:47,712 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=6705689&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-16 08:17:47,717 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=6705689&punumber=6287639: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=135.0.7049.85)
Stacktrace:
	GetHandleVerifier [0x01168073+60707]
	GetHandleVerifier [0x011680B4+60772]
	(No symbol) [0x00F90683]
	(No symbol) [0x00F6FBEE]
	(No symbol) [0x01003C2E]
	(No symbol) [0x0101E129]
	(No symbol) [0x00FFCE46]
	(No symbol) [0x00FCC5D3]
	(No symbol) [0x00FCD424]
	GetHandleVerifier [0x013ABB53+2435075]
	GetHandleVerifier [0x013A70F3+2416035]
	GetHandleVerifier [0x013C349C+2531660]
	GetHandleVerifier [0x0117F145+155125]
	GetHandleVerifier [0x01185AED+182173]
	GetHandleVerifier [0x0116F948+91640]
	GetHandleVerifier [0x0116FAF0+92064]
	GetHandleVerifier [0x0115A5B0+4704]
	BaseThreadInitThunk [0x76B6FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x774A82AE+286]
	RtlGetAppContainerNamedObjectPath [0x774A827E+238]

2025-04-16 08:17:47,718 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7042252&punumber=6287639
2025-04-16 08:17:47,718 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7042252&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-16 08:17:47,722 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7042252&punumber=6287639: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=135.0.7049.85)
Stacktrace:
	GetHandleVerifier [0x01168073+60707]
	GetHandleVerifier [0x011680B4+60772]
	(No symbol) [0x00F90683]
	(No symbol) [0x00F6FBEE]
	(No symbol) [0x01003C2E]
	(No symbol) [0x0101E129]
	(No symbol) [0x00FFCE46]
	(No symbol) [0x00FCC5D3]
	(No symbol) [0x00FCD424]
	GetHandleVerifier [0x013ABB53+2435075]
	GetHandleVerifier [0x013A70F3+2416035]
	GetHandleVerifier [0x013C349C+2531660]
	GetHandleVerifier [0x0117F145+155125]
	GetHandleVerifier [0x01185AED+182173]
	GetHandleVerifier [0x0116F948+91640]
	GetHandleVerifier [0x0116FAF0+92064]
	GetHandleVerifier [0x0115A5B0+4704]
	BaseThreadInitThunk [0x76B6FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x774A82AE+286]
	RtlGetAppContainerNamedObjectPath [0x774A827E+238]

2025-04-16 08:17:47,723 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7859429&punumber=6287639
2025-04-16 08:17:47,723 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7859429&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-16 08:17:47,732 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7859429&punumber=6287639: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=135.0.7049.85)
Stacktrace:
	GetHandleVerifier [0x01168073+60707]
	GetHandleVerifier [0x011680B4+60772]
	(No symbol) [0x00F90683]
	(No symbol) [0x00F6FBEE]
	(No symbol) [0x01003C2E]
	(No symbol) [0x0101E129]
	(No symbol) [0x00FFCE46]
	(No symbol) [0x00FCC5D3]
	(No symbol) [0x00FCD424]
	GetHandleVerifier [0x013ABB53+2435075]
	GetHandleVerifier [0x013A70F3+2416035]
	GetHandleVerifier [0x013C349C+2531660]
	GetHandleVerifier [0x0117F145+155125]
	GetHandleVerifier [0x01185AED+182173]
	GetHandleVerifier [0x0116F948+91640]
	GetHandleVerifier [0x0116FAF0+92064]
	GetHandleVerifier [0x0115A5B0+4704]
	BaseThreadInitThunk [0x76B6FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x774A82AE+286]
	RtlGetAppContainerNamedObjectPath [0x774A827E+238]

2025-04-16 08:17:47,733 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=9668973&punumber=6287639
2025-04-16 08:17:47,733 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=9668973&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-16 08:17:47,744 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=9668973&punumber=6287639: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=135.0.7049.85)
Stacktrace:
	GetHandleVerifier [0x01168073+60707]
	GetHandleVerifier [0x011680B4+60772]
	(No symbol) [0x00F90683]
	(No symbol) [0x00F6FBEE]
	(No symbol) [0x01003C2E]
	(No symbol) [0x0101E129]
	(No symbol) [0x00FFCE46]
	(No symbol) [0x00FCC5D3]
	(No symbol) [0x00FCD424]
	GetHandleVerifier [0x013ABB53+2435075]
	GetHandleVerifier [0x013A70F3+2416035]
	GetHandleVerifier [0x013C349C+2531660]
	GetHandleVerifier [0x0117F145+155125]
	GetHandleVerifier [0x01185AED+182173]
	GetHandleVerifier [0x0116F948+91640]
	GetHandleVerifier [0x0116FAF0+92064]
	GetHandleVerifier [0x0115A5B0+4704]
	BaseThreadInitThunk [0x76B6FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x774A82AE+286]
	RtlGetAppContainerNamedObjectPath [0x774A827E+238]

2025-04-16 08:17:47,745 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=9312710&punumber=6287639
2025-04-16 08:17:47,745 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=9312710&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-16 08:17:47,748 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=9312710&punumber=6287639: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=135.0.7049.85)
Stacktrace:
	GetHandleVerifier [0x01168073+60707]
	GetHandleVerifier [0x011680B4+60772]
	(No symbol) [0x00F90683]
	(No symbol) [0x00F6FBEE]
	(No symbol) [0x01003C2E]
	(No symbol) [0x0101E129]
	(No symbol) [0x00FFCE46]
	(No symbol) [0x00FCC5D3]
	(No symbol) [0x00FCD424]
	GetHandleVerifier [0x013ABB53+2435075]
	GetHandleVerifier [0x013A70F3+2416035]
	GetHandleVerifier [0x013C349C+2531660]
	GetHandleVerifier [0x0117F145+155125]
	GetHandleVerifier [0x01185AED+182173]
	GetHandleVerifier [0x0116F948+91640]
	GetHandleVerifier [0x0116FAF0+92064]
	GetHandleVerifier [0x0115A5B0+4704]
	BaseThreadInitThunk [0x76B6FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x774A82AE+286]
	RtlGetAppContainerNamedObjectPath [0x774A827E+238]

2025-04-16 08:17:47,749 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8600701&punumber=6287639
2025-04-16 08:17:47,750 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8600701&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-16 08:17:47,752 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8600701&punumber=6287639: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=135.0.7049.85)
Stacktrace:
	GetHandleVerifier [0x01168073+60707]
	GetHandleVerifier [0x011680B4+60772]
	(No symbol) [0x00F90683]
	(No symbol) [0x00F6FBEE]
	(No symbol) [0x01003C2E]
	(No symbol) [0x0101E129]
	(No symbol) [0x00FFCE46]
	(No symbol) [0x00FCC5D3]
	(No symbol) [0x00FCD424]
	GetHandleVerifier [0x013ABB53+2435075]
	GetHandleVerifier [0x013A70F3+2416035]
	GetHandleVerifier [0x013C349C+2531660]
	GetHandleVerifier [0x0117F145+155125]
	GetHandleVerifier [0x01185AED+182173]
	GetHandleVerifier [0x0116F948+91640]
	GetHandleVerifier [0x0116FAF0+92064]
	GetHandleVerifier [0x0115A5B0+4704]
	BaseThreadInitThunk [0x76B6FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x774A82AE+286]
	RtlGetAppContainerNamedObjectPath [0x774A827E+238]

2025-04-16 08:17:47,755 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10380310&punumber=6287639
2025-04-16 08:17:47,755 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10380310&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-16 08:17:47,762 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10380310&punumber=6287639: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=135.0.7049.85)
Stacktrace:
	GetHandleVerifier [0x01168073+60707]
	GetHandleVerifier [0x011680B4+60772]
	(No symbol) [0x00F90683]
	(No symbol) [0x00F6FBEE]
	(No symbol) [0x01003C2E]
	(No symbol) [0x0101E129]
	(No symbol) [0x00FFCE46]
	(No symbol) [0x00FCC5D3]
	(No symbol) [0x00FCD424]
	GetHandleVerifier [0x013ABB53+2435075]
	GetHandleVerifier [0x013A70F3+2416035]
	GetHandleVerifier [0x013C349C+2531660]
	GetHandleVerifier [0x0117F145+155125]
	GetHandleVerifier [0x01185AED+182173]
	GetHandleVerifier [0x0116F948+91640]
	GetHandleVerifier [0x0116FAF0+92064]
	GetHandleVerifier [0x0115A5B0+4704]
	BaseThreadInitThunk [0x76B6FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x774A82AE+286]
	RtlGetAppContainerNamedObjectPath [0x774A827E+238]

2025-04-16 08:17:47,763 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8948470&punumber=6287639
2025-04-16 08:17:47,763 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8948470&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-16 08:17:47,775 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8948470&punumber=6287639: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=135.0.7049.85)
Stacktrace:
	GetHandleVerifier [0x01168073+60707]
	GetHandleVerifier [0x011680B4+60772]
	(No symbol) [0x00F90683]
	(No symbol) [0x00F6FBEE]
	(No symbol) [0x01003C2E]
	(No symbol) [0x0101E129]
	(No symbol) [0x00FFCE46]
	(No symbol) [0x00FCC5D3]
	(No symbol) [0x00FCD424]
	GetHandleVerifier [0x013ABB53+2435075]
	GetHandleVerifier [0x013A70F3+2416035]
	GetHandleVerifier [0x013C349C+2531660]
	GetHandleVerifier [0x0117F145+155125]
	GetHandleVerifier [0x01185AED+182173]
	GetHandleVerifier [0x0116F948+91640]
	GetHandleVerifier [0x0116FAF0+92064]
	GetHandleVerifier [0x0115A5B0+4704]
	BaseThreadInitThunk [0x76B6FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x774A82AE+286]
	RtlGetAppContainerNamedObjectPath [0x774A827E+238]

2025-04-16 08:17:47,777 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7419931&punumber=6287639
2025-04-16 08:17:47,777 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7419931&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-16 08:17:47,781 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=7419931&punumber=6287639: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=135.0.7049.85)
Stacktrace:
	GetHandleVerifier [0x01168073+60707]
	GetHandleVerifier [0x011680B4+60772]
	(No symbol) [0x00F90683]
	(No symbol) [0x00F6FBEE]
	(No symbol) [0x01003C2E]
	(No symbol) [0x0101E129]
	(No symbol) [0x00FFCE46]
	(No symbol) [0x00FCC5D3]
	(No symbol) [0x00FCD424]
	GetHandleVerifier [0x013ABB53+2435075]
	GetHandleVerifier [0x013A70F3+2416035]
	GetHandleVerifier [0x013C349C+2531660]
	GetHandleVerifier [0x0117F145+155125]
	GetHandleVerifier [0x01185AED+182173]
	GetHandleVerifier [0x0116F948+91640]
	GetHandleVerifier [0x0116FAF0+92064]
	GetHandleVerifier [0x0115A5B0+4704]
	BaseThreadInitThunk [0x76B6FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x774A82AE+286]
	RtlGetAppContainerNamedObjectPath [0x774A827E+238]

2025-04-16 08:17:47,782 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=6336544&punumber=6287639
2025-04-16 08:17:47,782 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=6336544&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-16 08:17:47,786 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=6336544&punumber=6287639: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=135.0.7049.85)
Stacktrace:
	GetHandleVerifier [0x01168073+60707]
	GetHandleVerifier [0x011680B4+60772]
	(No symbol) [0x00F90683]
	(No symbol) [0x00F6FBEE]
	(No symbol) [0x01003C2E]
	(No symbol) [0x0101E129]
	(No symbol) [0x00FFCE46]
	(No symbol) [0x00FCC5D3]
	(No symbol) [0x00FCD424]
	GetHandleVerifier [0x013ABB53+2435075]
	GetHandleVerifier [0x013A70F3+2416035]
	GetHandleVerifier [0x013C349C+2531660]
	GetHandleVerifier [0x0117F145+155125]
	GetHandleVerifier [0x01185AED+182173]
	GetHandleVerifier [0x0116F948+91640]
	GetHandleVerifier [0x0116FAF0+92064]
	GetHandleVerifier [0x0115A5B0+4704]
	BaseThreadInitThunk [0x76B6FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x774A82AE+286]
	RtlGetAppContainerNamedObjectPath [0x774A827E+238]

2025-04-16 08:17:47,787 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639
2025-04-16 08:17:47,788 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-16 08:17:47,797 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=10005208&punumber=6287639: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=135.0.7049.85)
Stacktrace:
	GetHandleVerifier [0x01168073+60707]
	GetHandleVerifier [0x011680B4+60772]
	(No symbol) [0x00F90683]
	(No symbol) [0x00F6FBEE]
	(No symbol) [0x01003C2E]
	(No symbol) [0x0101E129]
	(No symbol) [0x00FFCE46]
	(No symbol) [0x00FCC5D3]
	(No symbol) [0x00FCD424]
	GetHandleVerifier [0x013ABB53+2435075]
	GetHandleVerifier [0x013A70F3+2416035]
	GetHandleVerifier [0x013C349C+2531660]
	GetHandleVerifier [0x0117F145+155125]
	GetHandleVerifier [0x01185AED+182173]
	GetHandleVerifier [0x0116F948+91640]
	GetHandleVerifier [0x0116FAF0+92064]
	GetHandleVerifier [0x0115A5B0+4704]
	BaseThreadInitThunk [0x76B6FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x774A82AE+286]
	RtlGetAppContainerNamedObjectPath [0x774A827E+238]

2025-04-16 08:17:47,797 - INFO - Mulai scraping dari: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8274985&punumber=6287639
2025-04-16 08:17:47,797 - INFO - \U0001f4c4 Membuka halaman 1: https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8274985&punumber=6287639&sortType=vol-only-newest&pageNumber=1
2025-04-16 08:17:47,801 - ERROR - \u274c Terjadi kesalahan saat scraping https://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=8274985&punumber=6287639: Message: no such window: target window already closed
from unknown error: web view not found
  (Session info: chrome=135.0.7049.85)
Stacktrace:
	GetHandleVerifier [0x01168073+60707]
	GetHandleVerifier [0x011680B4+60772]
	(No symbol) [0x00F90683]
	(No symbol) [0x00F6FBEE]
	(No symbol) [0x01003C2E]
	(No symbol) [0x0101E129]
	(No symbol) [0x00FFCE46]
	(No symbol) [0x00FCC5D3]
	(No symbol) [0x00FCD424]
	GetHandleVerifier [0x013ABB53+2435075]
	GetHandleVerifier [0x013A70F3+2416035]
	GetHandleVerifier [0x013C349C+2531660]
	GetHandleVerifier [0x0117F145+155125]
	GetHandleVerifier [0x01185AED+182173]
	GetHandleVerifier [0x0116F948+91640]
	GetHandleVerifier [0x0116FAF0+92064]
	GetHandleVerifier [0x0115A5B0+4704]
	BaseThreadInitThunk [0x76B6FCC9+25]
	RtlGetAppContainerNamedObjectPath [0x774A82AE+286]
	RtlGetAppContainerNamedObjectPath [0x774A827E+238]

Traceback (most recent call last):
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\socket.py", line 836, in create_connection
    sock.connect(sa)
TimeoutError: timed out

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\Satriock\Documents\Code\AI\MLOps\Topic Modelling\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 126, in <module>
    driver.quit()
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\selenium\webdriver\chromium\webdriver.py", line 193, in quit
    self.service.stop()
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\selenium\webdriver\common\service.py", line 157, in stop
    self.send_remote_shutdown_command()
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\selenium\webdriver\common\service.py", line 142, in send_remote_shutdown_command
    if not self.is_connectable():
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\selenium\webdriver\common\service.py", line 131, in is_connectable
    return utils.is_connectable(self.port)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\selenium\webdriver\common\utils.py", line 101, in is_connectable
    socket_ = socket.create_connection((host, port), 1)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\socket.py", line 843, in create_connection
    exceptions.clear()  # raise only the last error
    ^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

2025-04-16 08:17:52,159 - INFO - Memulai proses cleaning data...
2025-04-16 08:17:52,160 - INFO - Menjalankan script: cleaningdata.py
2025-04-16 08:17:53,070 - ERROR - Script cleaningdata.py gagal dijalankan.
2025-04-16 08:17:53,071 - ERROR - Traceback (most recent call last):
  File "C:\Users\Satriock\Documents\Code\AI\MLOps\Topic Modelling\Topic-Modelling-Article-Titles\src\scrapping\cleaningdata.py", line 1, in <module>
    import pandas as pd
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\__init__.py", line 148, in <module>
    from pandas import api, arrays, errors, io, plotting, tseries
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\api\__init__.py", line 2, in <module>
    from pandas.api import (
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\api\typing\__init__.py", line 31, in <module>
    from pandas.io.json._json import JsonReader
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\io\json\__init__.py", line 1, in <module>
    from pandas.io.json._json import (
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1138, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 1078, in _find_spec
  File "<frozen importlib._bootstrap_external>", line 1507, in find_spec
  File "<frozen importlib._bootstrap_external>", line 1479, in _get_spec
  File "<frozen importlib._bootstrap_external>", line 1646, in find_spec
  File "<frozen importlib._bootstrap>", line 244, in _verbose_message
KeyboardInterrupt

2025-04-16 08:17:53,074 - INFO - Scraping judul dan cleaning data selesai.
2025-04-16 08:17:53,074 - INFO - Seluruh proses selesai.
2025-04-16 15:28:15,037 - INFO - Menerima permintaan untuk menjalankan seluruh rangkaian proses.
2025-04-16 15:28:15,083 - INFO - Memulai seluruh rangkaian proses...
2025-04-16 15:28:15,084 - INFO - Memulai proses scraping link artikel...
2025-04-16 15:28:15,086 - INFO - Menjalankan script: getLinks.py
2025-04-16 15:28:25,066 - ERROR - Script getLinks.py gagal dijalankan.
2025-04-16 15:28:25,067 - ERROR - Traceback (most recent call last):
  File "C:\Users\Satriock\Documents\Code\AI\MLOps\Topic Modelling\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 71, in <module>
    scrape_ieee_links()
  File "C:\Users\Satriock\Documents\Code\AI\MLOps\Topic Modelling\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 37, in scrape_ieee_links
    driver = setup_driver()
             ^^^^^^^^^^^^^^
  File "C:\Users\Satriock\Documents\Code\AI\MLOps\Topic Modelling\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 20, in setup_driver
    service = Service(ChromeDriverManager().install())
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\chrome.py", line 40, in install
    driver_path = self._get_driver_binary_path(self.driver)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\core\manager.py", line 35, in _get_driver_binary_path
    binary_path = self._cache_manager.find_driver(driver)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\core\driver_cache.py", line 107, in find_driver
    driver_version = self.get_cache_key_driver_version(driver)
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\core\driver_cache.py", line 154, in get_cache_key_driver_version
    return driver.get_driver_version_to_download()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\core\driver.py", line 48, in get_driver_version_to_download
    return self.get_latest_release_version()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\drivers\chrome.py", line 59, in get_latest_release_version
    response = self._http_client.get(url)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\core\http.py", line 32, in get
    resp = requests.get(
           ^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\requests\api.py", line 73, in get
    return request("get", url, params=params, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\requests\api.py", line 59, in request
    return session.request(method=method, url=url, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\requests\sessions.py", line 589, in request
    resp = self.send(prep, **send_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\requests\sessions.py", line 703, in send
    r = adapter.send(request, **kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\requests\adapters.py", line 667, in send
    resp = conn.urlopen(
           ^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\connectionpool.py", line 789, in urlopen
    response = self._make_request(
               ^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\connectionpool.py", line 466, in _make_request
    self._validate_conn(conn)
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\connectionpool.py", line 1095, in _validate_conn
    conn.connect()
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\connection.py", line 730, in connect
    sock_and_verified = _ssl_wrap_socket_and_match_hostname(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\connection.py", line 909, in _ssl_wrap_socket_and_match_hostname
    ssl_sock = ssl_wrap_socket(
               ^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\util\ssl_.py", line 469, in ssl_wrap_socket
    ssl_sock = _ssl_wrap_socket_impl(sock, context, tls_in_tls, server_hostname)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\urllib3\util\ssl_.py", line 513, in _ssl_wrap_socket_impl
    return ssl_context.wrap_socket(sock, server_hostname=server_hostname)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\ssl.py", line 517, in wrap_socket
    return self.sslsocket_class._create(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\ssl.py", line 1104, in _create
    self.do_handshake()
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\ssl.py", line 1382, in do_handshake
    self._sslobj.do_handshake()
KeyboardInterrupt

2025-04-16 15:28:25,071 - INFO - Memulai scraping judul...
2025-04-16 15:28:25,071 - INFO - Menjalankan script: getTitle.py
2025-04-16 15:28:26,883 - ERROR - Script getTitle.py gagal dijalankan.
2025-04-16 15:28:26,883 - ERROR - Traceback (most recent call last):
  File "C:\Users\Satriock\Documents\Code\AI\MLOps\Topic Modelling\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 12, in <module>
    from webdriver_manager.chrome import ChromeDriverManager
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\chrome.py", line 4, in <module>
    from webdriver_manager.core.download_manager import DownloadManager
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\core\download_manager.py", line 5, in <module>
    from webdriver_manager.core.http import WDMHttpClient
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\core\http.py", line 1, in <module>
    import requests
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\requests\__init__.py", line 164, in <module>
    from .api import delete, get, head, options, patch, post, put, request
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\requests\api.py", line 11, in <module>
    from . import sessions
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\requests\sessions.py", line 15, in <module>
    from .adapters import HTTPAdapter
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\requests\adapters.py", line 81, in <module>
    _preloaded_ssl_context.load_verify_locations(
KeyboardInterrupt

2025-04-16 15:28:26,885 - INFO - Memulai proses cleaning data...
2025-04-16 15:28:26,885 - INFO - Menjalankan script: cleaningdata.py
2025-04-16 15:28:27,211 - ERROR - Script cleaningdata.py gagal dijalankan.
2025-04-16 15:28:27,211 - ERROR - Traceback (most recent call last):
  File "C:\Users\Satriock\Documents\Code\AI\MLOps\Topic Modelling\Topic-Modelling-Article-Titles\src\scrapping\cleaningdata.py", line 1, in <module>
    import pandas as pd
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\__init__.py", line 24, in <module>
    __import__(_dependency)
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\numpy\__init__.py", line 163, in <module>
    from . import lib
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\numpy\lib\__init__.py", line 23, in <module>
    from . import index_tricks
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\numpy\lib\index_tricks.py", line 12, in <module>
    import numpy.matrixlib as matrixlib
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\numpy\matrixlib\__init__.py", line 4, in <module>
    from . import defmatrix
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\numpy\matrixlib\defmatrix.py", line 12, in <module>
    from numpy.linalg import matrix_power
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\numpy\linalg\__init__.py", line 73, in <module>
    from . import linalg
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\numpy\linalg\linalg.py", line 37, in <module>
    from numpy._typing import NDArray
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\numpy\_typing\__init__.py", line 182, in <module>
    from ._array_like import (
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\numpy\_typing\_array_like.py", line 40, in <module>
    class _SupportsArray(Protocol[_DType_co]):
  File "<frozen abc>", line 106, in __new__
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\typing.py", line 2071, in __init_subclass__
    def __init_subclass__(cls, *args, **kwargs):

KeyboardInterrupt

2025-04-16 15:28:27,214 - INFO - Scraping judul dan cleaning data selesai.
2025-04-16 15:28:27,214 - INFO - Seluruh proses selesai.
2025-04-16 16:38:41,870 - INFO - Menerima permintaan untuk menjalankan seluruh rangkaian proses.
2025-04-16 16:38:41,884 - INFO - Memulai seluruh rangkaian proses...
2025-04-16 16:38:41,885 - INFO - Memulai proses scraping link artikel...
2025-04-16 16:38:41,885 - INFO - Menjalankan script: getLinks.py
2025-04-16 16:38:44,846 - ERROR - Script getLinks.py gagal dijalankan.
2025-04-16 16:38:44,846 - ERROR - Traceback (most recent call last):
  File "C:\Users\Satriock\Documents\Code\AI\MLOps\Topic Modelling\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 71, in <module>
    scrape_ieee_links()
  File "C:\Users\Satriock\Documents\Code\AI\MLOps\Topic Modelling\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 37, in scrape_ieee_links
    driver = setup_driver()
             ^^^^^^^^^^^^^^
  File "C:\Users\Satriock\Documents\Code\AI\MLOps\Topic Modelling\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 20, in setup_driver
    service = Service(ChromeDriverManager().install())
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\chrome.py", line 40, in install
    driver_path = self._get_driver_binary_path(self.driver)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\core\manager.py", line 35, in _get_driver_binary_path
    binary_path = self._cache_manager.find_driver(driver)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\core\driver_cache.py", line 103, in find_driver
    browser_version = self._os_system_manager.get_browser_version_from_os(browser_type)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\core\os_manager.py", line 159, in get_browser_version_from_os
    version = read_version_from_cmd(cmd_mapping, pattern)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\core\utils.py", line 46, in read_version_from_cmd
    stdout = stream.communicate()[0].decode()
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\subprocess.py", line 1196, in communicate
    stdout = self.stdout.read()
             ^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

2025-04-16 16:38:44,848 - INFO - Memulai scraping judul...
2025-04-16 16:38:44,848 - INFO - Menjalankan script: getTitle.py
2025-04-16 16:38:45,055 - ERROR - Script getTitle.py gagal dijalankan.
2025-04-16 16:38:45,055 - ERROR - Traceback (most recent call last):
  File "C:\Users\Satriock\Documents\Code\AI\MLOps\Topic Modelling\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 1, in <module>
    import pandas as pd
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\__init__.py", line 24, in <module>
    __import__(_dependency)
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\numpy\__init__.py", line 163, in <module>
    from . import lib
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\numpy\lib\__init__.py", line 23, in <module>
    from . import index_tricks
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\numpy\lib\index_tricks.py", line 12, in <module>
    import numpy.matrixlib as matrixlib
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\numpy\matrixlib\__init__.py", line 4, in <module>
    from . import defmatrix
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\numpy\matrixlib\defmatrix.py", line 12, in <module>
    from numpy.linalg import matrix_power
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\numpy\linalg\__init__.py", line 73, in <module>
    from . import linalg
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\numpy\linalg\linalg.py", line 35, in <module>
    from numpy.linalg import _umath_linalg
KeyboardInterrupt

2025-04-16 16:38:45,057 - INFO - Memulai proses cleaning data...
2025-04-16 16:38:45,057 - INFO - Menjalankan script: cleaningdata.py
2025-04-16 16:38:45,855 - ERROR - Script cleaningdata.py gagal dijalankan.
2025-04-16 16:38:45,856 - ERROR - Traceback (most recent call last):
  File "C:\Users\Satriock\Documents\Code\AI\MLOps\Topic Modelling\Topic-Modelling-Article-Titles\src\scrapping\cleaningdata.py", line 1, in <module>
    import pandas as pd
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\__init__.py", line 148, in <module>
    from pandas import api, arrays, errors, io, plotting, tseries
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\api\__init__.py", line 2, in <module>
    from pandas.api import (
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\api\typing\__init__.py", line 31, in <module>
    from pandas.io.json._json import JsonReader
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\io\json\__init__.py", line 1, in <module>
    from pandas.io.json._json import (
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\io\json\_json.py", line 67, in <module>
    from pandas.io.parsers.readers import validate_integer
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\io\parsers\__init__.py", line 1, in <module>
    from pandas.io.parsers.readers import (
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\io\parsers\readers.py", line 60, in <module>
    from pandas.io.parsers.python_parser import (
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1032, in get_code
  File "<frozen importlib._bootstrap_external>", line 1130, in get_data
KeyboardInterrupt

2025-04-16 16:38:45,858 - INFO - Scraping judul dan cleaning data selesai.
2025-04-16 16:38:45,858 - INFO - Seluruh proses selesai.
2025-04-16 16:50:18,864 - INFO - Menerima permintaan untuk menjalankan seluruh rangkaian proses.
2025-04-16 16:50:18,872 - INFO - Memulai seluruh rangkaian proses...
2025-04-16 16:50:18,873 - INFO - Memulai proses scraping link artikel...
2025-04-16 16:50:18,873 - INFO - Menjalankan script: getLinks.py
2025-04-16 16:50:21,811 - ERROR - Script getLinks.py gagal dijalankan.
2025-04-16 16:50:21,812 - ERROR - Traceback (most recent call last):
  File "C:\Users\Satriock\Documents\Code\AI\MLOps\Topic Modelling\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 71, in <module>
    scrape_ieee_links()
  File "C:\Users\Satriock\Documents\Code\AI\MLOps\Topic Modelling\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 37, in scrape_ieee_links
    driver = setup_driver()
             ^^^^^^^^^^^^^^
  File "C:\Users\Satriock\Documents\Code\AI\MLOps\Topic Modelling\Topic-Modelling-Article-Titles\src\scrapping\getLinks.py", line 20, in setup_driver
    service = Service(ChromeDriverManager().install())
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\chrome.py", line 40, in install
    driver_path = self._get_driver_binary_path(self.driver)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\core\manager.py", line 35, in _get_driver_binary_path
    binary_path = self._cache_manager.find_driver(driver)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\core\driver_cache.py", line 103, in find_driver
    browser_version = self._os_system_manager.get_browser_version_from_os(browser_type)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\core\os_manager.py", line 159, in get_browser_version_from_os
    version = read_version_from_cmd(cmd_mapping, pattern)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\webdriver_manager\core\utils.py", line 46, in read_version_from_cmd
    stdout = stream.communicate()[0].decode()
             ^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\Lib\subprocess.py", line 1196, in communicate
    stdout = self.stdout.read()
             ^^^^^^^^^^^^^^^^^^
KeyboardInterrupt

2025-04-16 16:50:21,813 - INFO - Memulai scraping judul...
2025-04-16 16:50:21,814 - INFO - Menjalankan script: getTitle.py
2025-04-16 16:50:22,384 - ERROR - Script getTitle.py gagal dijalankan.
2025-04-16 16:50:22,385 - ERROR - Traceback (most recent call last):
  File "C:\Users\Satriock\Documents\Code\AI\MLOps\Topic Modelling\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 1, in <module>
    import pandas as pd
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\__init__.py", line 59, in <module>
    from pandas.core.api import (
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\core\api.py", line 28, in <module>
    from pandas.core.arrays import Categorical
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\core\arrays\__init__.py", line 19, in <module>
    from pandas.core.arrays.sparse import SparseArray
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\core\arrays\sparse\__init__.py", line 1, in <module>
    from pandas.core.arrays.sparse.accessor import (
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\core\arrays\sparse\accessor.py", line 17, in <module>
    from pandas.core.arrays.sparse.array import SparseArray
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\core\arrays\sparse\array.py", line 83, in <module>
    from pandas.io.formats import printing
  File "<frozen importlib._bootstrap>", line 1176, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1147, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 690, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 936, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1032, in get_code
  File "<frozen importlib._bootstrap_external>", line 1130, in get_data
KeyboardInterrupt

2025-04-16 16:50:22,388 - INFO - Memulai proses cleaning data...
2025-04-16 16:50:22,388 - INFO - Menjalankan script: cleaningdata.py
2025-04-16 16:50:23,141 - ERROR - Script cleaningdata.py gagal dijalankan.
2025-04-16 16:50:23,142 - ERROR - Traceback (most recent call last):
  File "C:\Users\Satriock\Documents\Code\AI\MLOps\Topic Modelling\Topic-Modelling-Article-Titles\src\scrapping\cleaningdata.py", line 1, in <module>
    import pandas as pd
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\__init__.py", line 59, in <module>
    from pandas.core.api import (
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\core\api.py", line 47, in <module>
    from pandas.core.groupby import (
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\core\groupby\__init__.py", line 1, in <module>
    from pandas.core.groupby.generic import (
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\core\groupby\generic.py", line 67, in <module>
    from pandas.core.frame import DataFrame
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\core\frame.py", line 142, in <module>
    from pandas.core.generic import (
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\core\generic.py", line 146, in <module>
    from pandas.core import (
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\core\indexing.py", line 70, in <module>
    from pandas.core.indexes.api import (
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\core\indexes\api.py", line 20, in <module>
    from pandas.core.indexes.base import (
  File "C:\Users\Satriock\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\LocalCache\local-packages\Python311\site-packages\pandas\core\indexes\base.py", line 34, in <module>
    from pandas._libs.internals import BlockValuesRefs
  File "internals.pyx", line 1, in init pandas._libs.internals
  File "<frozen importlib._bootstrap>", line 216, in _lock_unlock_module
KeyboardInterrupt

2025-04-16 16:50:23,143 - INFO - Scraping judul dan cleaning data selesai.
2025-04-16 16:50:23,143 - INFO - Seluruh proses selesai.
=======
2025-04-16 08:43:31,692 - INFO - Memulai proses cleaning data...
2025-04-16 08:43:31,692 - INFO - Menjalankan script: cleaningdata.py
2025-04-16 08:43:32,342 - ERROR - Script cleaningdata.py gagal dijalankan.
2025-04-16 08:43:32,342 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\cleaningdata.py", line 14, in <module>
    df = pd.read_json(input_json_path)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 791, in read_json
    json_reader = JsonReader(
                  ^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 904, in __init__
    data = self._get_data_from_filepath(filepath_or_buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 960, in _get_data_from_filepath
    raise FileNotFoundError(f"File {filepath_or_buffer} does not exist")
FileNotFoundError: File ../../data/raw/scraped_articles.json does not exist

2025-04-16 08:43:32,342 - INFO - Scraping judul dan cleaning data selesai.
2025-04-16 08:43:32,342 - INFO - Seluruh proses selesai.
2025-04-16 08:43:39,829 - INFO - Menerima permintaan untuk menjalankan seluruh rangkaian proses.
2025-04-16 08:43:39,841 - INFO - Memulai seluruh rangkaian proses...
2025-04-16 08:43:39,841 - INFO - Memulai proses scraping link artikel...
2025-04-16 08:43:39,842 - INFO - Menjalankan script: getLinks.py
2025-04-16 08:43:40,854 - INFO - Script getLinks.py selesai tanpa error.
2025-04-16 08:43:40,854 - INFO - Memulai scraping judul...
2025-04-16 08:43:40,854 - INFO - Menjalankan script: getTitle.py
2025-04-16 08:43:42,088 - ERROR - Script getTitle.py gagal dijalankan.
2025-04-16 08:43:42,088 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 121, in <module>
    driver = setup_driver()
             ^^^^^^^^^^^^^^
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 29, in setup_driver
    service = Service(ChromeDriverManager(version="114.0.5735.90").install())
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: ChromeDriverManager.__init__() got an unexpected keyword argument 'version'

2025-04-16 08:43:42,088 - INFO - Memulai proses cleaning data...
2025-04-16 08:43:42,088 - INFO - Menjalankan script: cleaningdata.py
2025-04-16 08:43:42,732 - ERROR - Script cleaningdata.py gagal dijalankan.
2025-04-16 08:43:42,732 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\cleaningdata.py", line 14, in <module>
    df = pd.read_json(input_json_path)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 791, in read_json
    json_reader = JsonReader(
                  ^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 904, in __init__
    data = self._get_data_from_filepath(filepath_or_buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 960, in _get_data_from_filepath
    raise FileNotFoundError(f"File {filepath_or_buffer} does not exist")
FileNotFoundError: File ../../data/raw/scraped_articles.json does not exist

2025-04-16 08:43:42,732 - INFO - Scraping judul dan cleaning data selesai.
2025-04-16 08:43:42,732 - INFO - Seluruh proses selesai.
2025-04-16 08:44:42,825 - INFO - Menerima permintaan untuk menjalankan seluruh rangkaian proses.
2025-04-16 08:44:42,833 - INFO - Memulai seluruh rangkaian proses...
2025-04-16 08:44:42,834 - INFO - Memulai proses scraping link artikel...
2025-04-16 08:44:42,834 - INFO - Menjalankan script: getLinks.py
2025-04-16 08:45:00,657 - INFO - Script getLinks.py selesai tanpa error.
2025-04-16 08:45:00,657 - INFO - Memulai scraping judul...
2025-04-16 08:45:00,657 - INFO - Menjalankan script: getTitle.py
2025-04-16 08:45:02,223 - ERROR - Script getTitle.py gagal dijalankan.
2025-04-16 08:45:02,224 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 121, in <module>
    driver = setup_driver()
             ^^^^^^^^^^^^^^
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 29, in setup_driver
    service = Service(ChromeDriverManager(version="114.0.5735.90").install())
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: ChromeDriverManager.__init__() got an unexpected keyword argument 'version'

2025-04-16 08:45:02,224 - INFO - Memulai proses cleaning data...
2025-04-16 08:45:02,224 - INFO - Menjalankan script: cleaningdata.py
2025-04-16 08:45:02,904 - ERROR - Script cleaningdata.py gagal dijalankan.
2025-04-16 08:45:02,904 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\cleaningdata.py", line 14, in <module>
    df = pd.read_json(input_json_path)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 791, in read_json
    json_reader = JsonReader(
                  ^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 904, in __init__
    data = self._get_data_from_filepath(filepath_or_buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 960, in _get_data_from_filepath
    raise FileNotFoundError(f"File {filepath_or_buffer} does not exist")
FileNotFoundError: File ../../data/raw/scraped_articles.json does not exist

2025-04-16 08:45:02,904 - INFO - Scraping judul dan cleaning data selesai.
2025-04-16 08:45:02,904 - INFO - Seluruh proses selesai.
2025-04-16 08:47:22,596 - INFO - Menerima permintaan untuk menjalankan seluruh rangkaian proses.
2025-04-16 08:47:22,606 - INFO - Memulai seluruh rangkaian proses...
2025-04-16 08:47:22,606 - INFO - Memulai proses scraping link artikel...
2025-04-16 08:47:22,607 - INFO - Menjalankan script: getLinks.py
2025-04-16 08:47:40,283 - INFO - Script getLinks.py selesai tanpa error.
2025-04-16 08:47:40,283 - INFO - Memulai scraping judul...
2025-04-16 08:47:40,283 - INFO - Menjalankan script: getTitle.py
2025-04-16 08:47:41,503 - ERROR - Script getTitle.py gagal dijalankan.
2025-04-16 08:47:41,504 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 121, in <module>
    driver = setup_driver()
             ^^^^^^^^^^^^^^
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 29, in setup_driver
    service = Service(ChromeDriverManager(version="114.0.5735.90").install())
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: ChromeDriverManager.__init__() got an unexpected keyword argument 'version'

2025-04-16 08:47:41,504 - INFO - Memulai proses cleaning data...
2025-04-16 08:47:41,504 - INFO - Menjalankan script: cleaningdata.py
2025-04-16 08:47:42,205 - ERROR - Script cleaningdata.py gagal dijalankan.
2025-04-16 08:47:42,207 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\cleaningdata.py", line 14, in <module>
    df = pd.read_json(input_json_path)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 791, in read_json
    json_reader = JsonReader(
                  ^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 904, in __init__
    data = self._get_data_from_filepath(filepath_or_buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 960, in _get_data_from_filepath
    raise FileNotFoundError(f"File {filepath_or_buffer} does not exist")
FileNotFoundError: File ../../data/raw/scraped_articles.json does not exist

2025-04-16 08:47:42,207 - INFO - Scraping judul dan cleaning data selesai.
2025-04-16 08:47:42,207 - INFO - Seluruh proses selesai.
2025-04-16 08:49:35,810 - INFO - Menerima permintaan untuk menjalankan seluruh rangkaian proses.
2025-04-16 08:49:35,818 - INFO - Memulai seluruh rangkaian proses...
2025-04-16 08:49:35,819 - INFO - Memulai proses scraping link artikel...
2025-04-16 08:49:35,819 - INFO - Menjalankan script: getLinks.py
2025-04-16 08:49:36,957 - INFO - Script getLinks.py selesai tanpa error.
2025-04-16 08:49:36,957 - INFO - Memulai scraping judul...
2025-04-16 08:49:36,957 - INFO - Menjalankan script: getTitle.py
2025-04-16 08:49:37,998 - ERROR - Script getTitle.py gagal dijalankan.
2025-04-16 08:49:37,998 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\common\driver_finder.py", line 64, in _binary_paths
    raise ValueError(f"The path is not a valid file: {path}")
ValueError: The path is not a valid file: C:/webdrivers/chromedriver.exe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 121, in <module>
    driver = setup_driver()
             ^^^^^^^^^^^^^^
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 38, in setup_driver
    return webdriver.Chrome(service=service, options=options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\chrome\webdriver.py", line 45, in __init__
    super().__init__(
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\chromium\webdriver.py", line 50, in __init__
    if finder.get_browser_path():
       ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\common\driver_finder.py", line 47, in get_browser_path
    return self._binary_paths()["browser_path"]
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\common\driver_finder.py", line 78, in _binary_paths
    raise NoSuchDriverException(msg) from err
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location


2025-04-16 08:49:38,008 - INFO - Memulai proses cleaning data...
2025-04-16 08:49:38,008 - INFO - Menjalankan script: cleaningdata.py
2025-04-16 08:49:38,675 - ERROR - Script cleaningdata.py gagal dijalankan.
2025-04-16 08:49:38,675 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\cleaningdata.py", line 14, in <module>
    df = pd.read_json(input_json_path)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 791, in read_json
    json_reader = JsonReader(
                  ^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 904, in __init__
    data = self._get_data_from_filepath(filepath_or_buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 960, in _get_data_from_filepath
    raise FileNotFoundError(f"File {filepath_or_buffer} does not exist")
FileNotFoundError: File ../../data/raw/scraped_articles.json does not exist

2025-04-16 08:49:38,679 - INFO - Scraping judul dan cleaning data selesai.
2025-04-16 08:49:38,679 - INFO - Seluruh proses selesai.
2025-04-16 08:52:07,053 - INFO - Menerima permintaan untuk menjalankan seluruh rangkaian proses.
2025-04-16 08:52:07,061 - INFO - Memulai seluruh rangkaian proses...
2025-04-16 08:52:07,061 - INFO - Memulai proses scraping link artikel...
2025-04-16 08:52:07,061 - INFO - Menjalankan script: getLinks.py
2025-04-16 08:52:08,125 - INFO - Script getLinks.py selesai tanpa error.
2025-04-16 08:52:08,126 - INFO - Memulai scraping judul...
2025-04-16 08:52:08,126 - INFO - Menjalankan script: getTitle.py
2025-04-16 08:52:09,199 - ERROR - Script getTitle.py gagal dijalankan.
2025-04-16 08:52:09,199 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\common\driver_finder.py", line 64, in _binary_paths
    raise ValueError(f"The path is not a valid file: {path}")
ValueError: The path is not a valid file: C:/webdrivers/chromedriver.exe

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 121, in <module>
    driver = setup_driver()
             ^^^^^^^^^^^^^^
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 38, in setup_driver
    return webdriver.Chrome(service=service, options=options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\chrome\webdriver.py", line 45, in __init__
    super().__init__(
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\chromium\webdriver.py", line 50, in __init__
    if finder.get_browser_path():
       ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\common\driver_finder.py", line 47, in get_browser_path
    return self._binary_paths()["browser_path"]
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\common\driver_finder.py", line 78, in _binary_paths
    raise NoSuchDriverException(msg) from err
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location


2025-04-16 08:52:09,199 - INFO - Memulai proses cleaning data...
2025-04-16 08:52:09,199 - INFO - Menjalankan script: cleaningdata.py
2025-04-16 08:52:09,975 - ERROR - Script cleaningdata.py gagal dijalankan.
2025-04-16 08:52:09,975 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\cleaningdata.py", line 14, in <module>
    df = pd.read_json(input_json_path)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 791, in read_json
    json_reader = JsonReader(
                  ^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 904, in __init__
    data = self._get_data_from_filepath(filepath_or_buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 960, in _get_data_from_filepath
    raise FileNotFoundError(f"File {filepath_or_buffer} does not exist")
FileNotFoundError: File ../../data/raw/scraped_articles.json does not exist

2025-04-16 08:52:09,975 - INFO - Scraping judul dan cleaning data selesai.
2025-04-16 08:52:09,975 - INFO - Seluruh proses selesai.
2025-04-16 12:26:17,334 - INFO - Menerima permintaan untuk menjalankan seluruh rangkaian proses.
2025-04-16 12:26:17,384 - INFO - Memulai seluruh rangkaian proses...
2025-04-16 12:26:17,386 - INFO - Memulai proses scraping link artikel...
2025-04-16 12:26:17,387 - INFO - Menjalankan script: getLinks.py
2025-04-16 12:26:21,995 - INFO - Script getLinks.py selesai tanpa error.
2025-04-16 12:26:21,995 - INFO - Memulai scraping judul...
2025-04-16 12:26:21,995 - INFO - Menjalankan script: getTitle.py
2025-04-16 12:26:24,410 - ERROR - Script getTitle.py gagal dijalankan.
2025-04-16 12:26:24,410 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\common\driver_finder.py", line 64, in _binary_paths
    raise ValueError(f"The path is not a valid file: {path}")
ValueError: The path is not a valid file: /usr/bin/chromedriver

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 121, in <module>
    driver = setup_driver()
             ^^^^^^^^^^^^^^
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 38, in setup_driver
    return webdriver.Chrome(service=service, options=options)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\chrome\webdriver.py", line 45, in __init__
    super().__init__(
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\chromium\webdriver.py", line 50, in __init__
    if finder.get_browser_path():
       ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\common\driver_finder.py", line 47, in get_browser_path
    return self._binary_paths()["browser_path"]
           ^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\selenium\webdriver\common\driver_finder.py", line 78, in _binary_paths
    raise NoSuchDriverException(msg) from err
selenium.common.exceptions.NoSuchDriverException: Message: Unable to obtain driver for chrome; For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors/driver_location


2025-04-16 12:26:24,414 - INFO - Memulai proses cleaning data...
2025-04-16 12:26:24,414 - INFO - Menjalankan script: cleaningdata.py
2025-04-16 12:26:25,782 - ERROR - Script cleaningdata.py gagal dijalankan.
2025-04-16 12:26:25,782 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\cleaningdata.py", line 14, in <module>
    df = pd.read_json(input_json_path)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 791, in read_json
    json_reader = JsonReader(
                  ^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 904, in __init__
    data = self._get_data_from_filepath(filepath_or_buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 960, in _get_data_from_filepath
    raise FileNotFoundError(f"File {filepath_or_buffer} does not exist")
FileNotFoundError: File ../../data/raw/scraped_articles.json does not exist

2025-04-16 12:26:25,782 - INFO - Scraping judul dan cleaning data selesai.
2025-04-16 12:26:25,782 - INFO - Seluruh proses selesai.
2025-04-16 20:15:46,580 - INFO - Menerima permintaan untuk streaming scraping judul dan cleaning.
2025-04-16 20:15:46,603 - INFO - Menjalankan script: getTitle.py
2025-04-16 20:17:17,033 - INFO - Script getTitle.py selesai.

2025-04-16 20:17:17,033 - INFO - Menjalankan script: cleaningdata.py
2025-04-16 20:17:18,102 - INFO - Script cleaningdata.py selesai.

2025-04-16 20:17:23,090 - INFO - Menerima permintaan untuk streaming scraping judul dan cleaning.
2025-04-16 20:17:23,106 - INFO - Menjalankan script: getTitle.py
2025-04-16 20:24:04,338 - INFO - Script getTitle.py selesai.

2025-04-16 20:24:17,430 - INFO - Menerima permintaan untuk streaming scraping judul dan cleaning.
2025-04-16 20:24:17,439 - INFO - Menjalankan script: getTitle.py
2025-04-16 20:32:28,754 - INFO - Script getTitle.py selesai.

2025-04-16 20:32:47,227 - INFO - Menerima permintaan untuk streaming scraping judul dan cleaning.
2025-04-16 20:32:47,243 - INFO - Menjalankan script: getTitle.py
2025-04-16 20:34:30,916 - INFO - Script getTitle.py selesai.

2025-04-16 20:34:46,566 - INFO - Menerima permintaan untuk streaming scraping judul dan cleaning.
2025-04-16 20:34:46,578 - INFO - Menjalankan script: getTitle.py
2025-04-16 20:37:50,361 - INFO - Script getTitle.py selesai.

2025-04-16 20:37:50,361 - INFO - Menjalankan script: cleaningdata.py
2025-04-16 20:37:55,186 - INFO - Menerima permintaan untuk streaming scraping judul dan cleaning.
2025-04-16 20:37:55,199 - INFO - Menjalankan script: getTitle.py
2025-04-16 20:37:55,423 - INFO - Menerima permintaan untuk streaming scraping judul dan cleaning.
2025-04-16 20:37:55,429 - INFO - Menjalankan script: getTitle.py
2025-04-16 20:37:56,780 - INFO - Script getTitle.py selesai.

2025-04-16 20:37:56,780 - INFO - Menjalankan script: cleaningdata.py
2025-04-16 20:37:56,897 - INFO - Script getTitle.py selesai.

2025-04-16 20:37:56,897 - INFO - Menjalankan script: cleaningdata.py
2025-04-16 20:37:57,617 - INFO - Script cleaningdata.py selesai.

2025-04-16 20:37:57,726 - INFO - Script cleaningdata.py selesai.

2025-04-16 20:40:28,610 - INFO - Menerima permintaan untuk streaming scraping judul dan cleaning.
2025-04-16 20:40:28,621 - INFO - Menjalankan script: getTitle.py
2025-04-16 20:40:30,083 - INFO - Script getTitle.py selesai.

2025-04-16 20:40:30,088 - INFO - Menjalankan script: cleaningdata.py
2025-04-16 20:40:30,823 - INFO - Script cleaningdata.py selesai.

2025-04-16 20:41:11,139 - INFO - Menerima permintaan untuk menjalankan seluruh rangkaian proses.
2025-04-16 20:41:11,142 - INFO - Memulai seluruh rangkaian proses...
2025-04-16 20:41:11,142 - INFO - Memulai proses scraping link artikel...
2025-04-16 20:41:11,142 - INFO - Menjalankan script: getLinks.py
2025-04-16 20:41:12,538 - INFO - Script getLinks.py selesai tanpa error.
2025-04-16 20:41:12,538 - INFO - Memulai scraping judul...
2025-04-16 20:41:12,548 - INFO - Menjalankan script: getTitle.py
2025-04-16 20:41:13,879 - ERROR - Script getTitle.py gagal dijalankan.
2025-04-16 20:41:13,880 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 128, in <module>
    driver = setup_driver()
             ^^^^^^^^^^^^
NameError: name 'setup_driver' is not defined. Did you mean: 'get_driver'?

2025-04-16 20:41:13,880 - INFO - Memulai proses cleaning data...
2025-04-16 20:41:13,880 - INFO - Menjalankan script: cleaningdata.py
2025-04-16 20:41:14,638 - ERROR - Script cleaningdata.py gagal dijalankan.
2025-04-16 20:41:14,638 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\cleaningdata.py", line 14, in <module>
    df = pd.read_json(input_json_path)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 791, in read_json
    json_reader = JsonReader(
                  ^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 904, in __init__
    data = self._get_data_from_filepath(filepath_or_buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 960, in _get_data_from_filepath
    raise FileNotFoundError(f"File {filepath_or_buffer} does not exist")
FileNotFoundError: File ../../data/raw/scraped_articles.json does not exist

2025-04-16 20:41:14,638 - INFO - Scraping judul dan cleaning data selesai.
2025-04-16 20:41:14,638 - INFO - Seluruh proses selesai.
2025-04-16 20:43:22,759 - INFO - Menerima permintaan untuk menjalankan seluruh rangkaian proses.
2025-04-16 20:43:22,768 - INFO - Memulai seluruh rangkaian proses...
2025-04-16 20:43:22,769 - INFO - Memulai proses scraping link artikel...
2025-04-16 20:43:22,769 - INFO - Menjalankan script: getLinks.py
2025-04-16 20:43:24,056 - INFO - Script getLinks.py selesai tanpa error.
2025-04-16 20:43:24,056 - INFO - Memulai scraping judul...
2025-04-16 20:43:24,056 - INFO - Menjalankan script: getTitle.py
2025-04-16 20:43:25,259 - ERROR - Script getTitle.py gagal dijalankan.
2025-04-16 20:43:25,259 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 128, in <module>
    driver = setup_driver()
             ^^^^^^^^^^^^
NameError: name 'setup_driver' is not defined. Did you mean: 'get_driver'?

2025-04-16 20:43:25,259 - INFO - Memulai proses cleaning data...
2025-04-16 20:43:25,259 - INFO - Menjalankan script: cleaningdata.py
2025-04-16 20:43:25,978 - ERROR - Script cleaningdata.py gagal dijalankan.
2025-04-16 20:43:25,978 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\cleaningdata.py", line 14, in <module>
    df = pd.read_json(input_json_path)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 791, in read_json
    json_reader = JsonReader(
                  ^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 904, in __init__
    data = self._get_data_from_filepath(filepath_or_buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 960, in _get_data_from_filepath
    raise FileNotFoundError(f"File {filepath_or_buffer} does not exist")
FileNotFoundError: File ../../data/raw/scraped_articles.json does not exist

2025-04-16 20:43:25,978 - INFO - Scraping judul dan cleaning data selesai.
2025-04-16 20:43:25,978 - INFO - Seluruh proses selesai.
2025-04-16 20:44:20,044 - INFO - Menerima permintaan untuk menjalankan seluruh rangkaian proses.
2025-04-16 20:44:20,057 - INFO - Memulai seluruh rangkaian proses...
2025-04-16 20:44:20,058 - INFO - Memulai proses scraping link artikel...
2025-04-16 20:44:20,058 - INFO - Menjalankan script: getLinks.py
2025-04-16 20:44:21,382 - INFO - Script getLinks.py selesai tanpa error.
2025-04-16 20:44:21,382 - INFO - Memulai scraping judul...
2025-04-16 20:44:21,382 - INFO - Menjalankan script: getTitle.py
2025-04-16 20:44:22,587 - ERROR - Script getTitle.py gagal dijalankan.
2025-04-16 20:44:22,587 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\getTitle.py", line 128, in <module>
    driver = setup_driver()
             ^^^^^^^^^^^^
NameError: name 'setup_driver' is not defined. Did you mean: 'get_driver'?

2025-04-16 20:44:22,589 - INFO - Memulai proses cleaning data...
2025-04-16 20:44:22,589 - INFO - Menjalankan script: cleaningdata.py
2025-04-16 20:44:23,311 - ERROR - Script cleaningdata.py gagal dijalankan.
2025-04-16 20:44:23,311 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\cleaningdata.py", line 14, in <module>
    df = pd.read_json(input_json_path)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 791, in read_json
    json_reader = JsonReader(
                  ^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 904, in __init__
    data = self._get_data_from_filepath(filepath_or_buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 960, in _get_data_from_filepath
    raise FileNotFoundError(f"File {filepath_or_buffer} does not exist")
FileNotFoundError: File ../../data/raw/scraped_articles.json does not exist

2025-04-16 20:44:23,311 - INFO - Scraping judul dan cleaning data selesai.
2025-04-16 20:44:23,312 - INFO - Seluruh proses selesai.
2025-04-16 20:45:31,294 - INFO - Menerima permintaan untuk menjalankan seluruh rangkaian proses.
2025-04-16 20:45:31,309 - INFO - Memulai seluruh rangkaian proses...
2025-04-16 20:45:31,309 - INFO - Memulai proses scraping link artikel...
2025-04-16 20:45:31,309 - INFO - Menjalankan script: getLinks.py
2025-04-16 20:46:08,387 - INFO - Script getLinks.py selesai tanpa error.
2025-04-16 20:46:08,390 - INFO - Memulai scraping judul...
2025-04-16 20:46:08,390 - INFO - Menjalankan script: getTitle.py
2025-04-16 20:48:17,082 - INFO - Script getTitle.py selesai tanpa error.
2025-04-16 20:48:17,084 - INFO - Memulai proses cleaning data...
2025-04-16 20:48:17,085 - INFO - Menjalankan script: cleaningdata.py
2025-04-16 20:48:20,286 - ERROR - Script cleaningdata.py gagal dijalankan.
2025-04-16 20:48:20,286 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\cleaningdata.py", line 14, in <module>
    df = pd.read_json(input_json_path)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 791, in read_json
    json_reader = JsonReader(
                  ^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 904, in __init__
    data = self._get_data_from_filepath(filepath_or_buffer)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 960, in _get_data_from_filepath
    raise FileNotFoundError(f"File {filepath_or_buffer} does not exist")
FileNotFoundError: File ../../data/raw/scraped_articles.json does not exist

2025-04-16 20:48:20,290 - INFO - Scraping judul dan cleaning data selesai.
2025-04-16 20:48:20,290 - INFO - Seluruh proses selesai.
2025-04-16 20:51:28,041 - INFO - Menerima permintaan untuk menjalankan seluruh rangkaian proses.
2025-04-16 20:51:28,058 - INFO - Memulai seluruh rangkaian proses...
2025-04-16 20:51:28,058 - INFO - Memulai proses scraping link artikel...
2025-04-16 20:51:28,058 - INFO - Menjalankan script: getLinks.py
2025-04-16 20:52:00,867 - INFO - Script getLinks.py selesai tanpa error.
2025-04-16 20:52:00,868 - INFO - Memulai scraping judul...
2025-04-16 20:52:00,869 - INFO - Menjalankan script: getTitle.py
2025-04-16 20:53:54,802 - INFO - Script getTitle.py selesai tanpa error.
2025-04-16 20:53:54,802 - INFO - Memulai proses cleaning data...
2025-04-16 20:53:54,802 - INFO - Menjalankan script: cleaningdata.py
2025-04-16 20:53:56,852 - ERROR - Script cleaningdata.py gagal dijalankan.
2025-04-16 20:53:56,852 - ERROR - Traceback (most recent call last):
  File "C:\Users\USER\Documents\Kumara\Topic-Modelling-Article-Titles\src\scrapping\cleaningdata.py", line 28, in <module>
    df.to_json(output_json_path, orient="records", indent=4, force_ascii=False)
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\util\_decorators.py", line 333, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\core\generic.py", line 2702, in to_json
    return json.to_json(
           ^^^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\json\_json.py", line 217, in to_json
    with get_handle(
         ^^^^^^^^^^^
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\common.py", line 749, in get_handle
    check_parent_directory(str(handle))
  File "C:\Users\USER\AppData\Local\Programs\Python\Python311\Lib\site-packages\pandas\io\common.py", line 616, in check_parent_directory
    raise OSError(rf"Cannot save file into a non-existent directory: '{parent}'")
OSError: Cannot save file into a non-existent directory: '..\..\data\cleaned'

2025-04-16 20:53:56,852 - INFO - Scraping judul dan cleaning data selesai.
2025-04-16 20:53:56,854 - INFO - Seluruh proses selesai.
2025-04-16 20:57:12,026 - INFO - Menerima permintaan untuk streaming scraping judul dan cleaning.
2025-04-16 20:57:12,044 - INFO - Menjalankan script: getTitle.py
2025-04-16 21:05:29,762 - INFO - Script getTitle.py selesai.

2025-04-17 09:22:51,368 - INFO - Menerima permintaan untuk streaming scraping judul dan cleaning.
2025-04-17 09:22:51,391 - INFO - Menjalankan script: getTitle.py
2025-04-17 09:26:22,136 - INFO - Script getTitle.py selesai.

2025-04-17 09:26:27,759 - INFO - Menerima permintaan untuk streaming scraping judul dan cleaning.
2025-04-17 09:26:27,772 - INFO - Menjalankan script: getTitle.py
2025-04-17 09:29:32,243 - INFO - Script getTitle.py selesai.

2025-04-17 09:29:38,745 - INFO - Menerima permintaan untuk streaming scraping judul dan cleaning.
2025-04-17 09:29:38,766 - INFO - Menjalankan script: getTitle.py
2025-04-17 09:32:18,839 - INFO - Script getTitle.py selesai.

2025-04-17 09:32:23,476 - INFO - Menerima permintaan untuk streaming scraping judul dan cleaning.
2025-04-17 09:32:23,493 - INFO - Menjalankan script: getTitle.py
2025-04-17 09:38:13,770 - INFO - Script getTitle.py selesai.

2025-04-17 09:38:22,250 - INFO - Menerima permintaan untuk streaming scraping judul dan cleaning.
2025-04-17 09:38:22,265 - INFO - Menjalankan script: getTitle.py
2025-04-17 09:38:28,995 - INFO - Script getTitle.py selesai.

2025-04-17 09:38:28,995 - INFO - Menjalankan script: cleaningdata.py
2025-04-17 09:38:30,470 - INFO - Script cleaningdata.py selesai.

2025-04-17 09:39:34,685 - INFO - Menerima permintaan untuk streaming scraping judul dan cleaning.
2025-04-17 09:39:34,713 - INFO - Menjalankan script: getTitle.py
2025-04-17 09:39:37,762 - INFO - Script getTitle.py selesai.

2025-04-17 09:39:37,762 - INFO - Menjalankan script: cleaningdata.py
2025-04-17 09:39:39,247 - INFO - Script cleaningdata.py selesai.

2025-04-17 09:40:46,886 - INFO - Menerima permintaan untuk streaming scraping judul dan cleaning.
2025-04-17 09:40:46,902 - INFO - Menjalankan script: getTitle.py
2025-04-17 09:42:53,934 - INFO - Script getTitle.py selesai.

2025-04-17 09:42:53,934 - INFO - Menjalankan script: cleaningdata.py
2025-04-17 09:42:59,594 - INFO - Menerima permintaan untuk streaming scraping judul dan cleaning.
2025-04-17 09:42:59,612 - INFO - Menjalankan script: getTitle.py
2025-04-17 09:43:42,203 - INFO - Script getTitle.py selesai.

2025-04-17 09:43:49,533 - INFO - Menerima permintaan untuk streaming scraping judul dan cleaning.
2025-04-17 09:43:49,556 - INFO - Menjalankan script: getTitle.py
2025-04-17 09:46:32,940 - INFO - Script getTitle.py selesai.

2025-04-17 09:46:38,528 - INFO - Menerima permintaan untuk streaming scraping judul dan cleaning.
2025-04-17 09:46:38,549 - INFO - Menjalankan script: getTitle.py
2025-04-17 09:50:14,718 - INFO - Script getTitle.py selesai.

2025-04-17 09:50:30,164 - INFO - Menerima permintaan untuk streaming scraping judul dan cleaning.
2025-04-17 09:50:30,179 - INFO - Menjalankan script: getTitle.py
2025-04-17 09:59:14,132 - INFO - Script getTitle.py selesai.

2025-04-17 09:59:22,375 - INFO - Menerima permintaan untuk streaming scraping judul dan cleaning.
2025-04-17 09:59:22,395 - INFO - Menjalankan script: getTitle.py
2025-04-17 10:05:01,123 - INFO - Script getTitle.py selesai.

2025-04-17 22:17:19,400 - INFO - Menerima permintaan untuk streaming scraping judul dan cleaning.
2025-04-17 22:17:19,429 - INFO - Menjalankan script: getTitle.py
2025-04-17 22:37:39,923 - INFO - Script getTitle.py selesai.

>>>>>>> abiyyu-v-crawling
